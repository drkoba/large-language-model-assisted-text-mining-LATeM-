{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drkoba/large-language-model-assisted-text-mining-LATeM-/blob/main/LATeM.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnVFzVzyBDSo",
        "outputId": "4ab76258-8cc3-49d6-ecdb-4a7bf828e2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: nltk 3.9.1\n",
            "Uninstalling nltk-3.9.1:\n",
            "  Successfully uninstalled nltk-3.9.1\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Collecting openai\n",
            "  Downloading openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.5)\n",
            "Collecting numexpr (from pyLDAvis)\n",
            "  Downloading numexpr-2.10.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from plotly) (1.26.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Downloading openai-1.63.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Downloading numexpr-2.10.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (398 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.9/398.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: funcy, xlsxwriter, PyPDF2, plotly, numexpr, nltk, jiter, h11, et-xmlfile, pandas, openpyxl, httpcore, pyLDAvis, httpx, openai\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 et-xmlfile-2.0.0 funcy-2.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 nltk-3.9.1 numexpr-2.10.2 openai-1.63.2 openpyxl-3.1.5 pandas-2.2.3 plotly-6.0.0 pyLDAvis-3.4.1 xlsxwriter-3.2.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Installation of Required Packages and Importing Libraries\n",
        "# Installing necessary packages\n",
        "!pip uninstall -y nltk\n",
        "!pip uninstall -y pandas\n",
        "!pip install --upgrade openai nltk pandas gensim pyLDAvis openpyxl xlsxwriter matplotlib networkx plotly scikit-learn PyPDF2\n",
        "!pip install pandas\n",
        "\n",
        "# Clearing the NLTK data directory\n",
        "import nltk\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "nltk_data_dir = os.path.expanduser('~/nltk_data')\n",
        "if os.path.exists(nltk_data_dir):\n",
        "    shutil.rmtree(nltk_data_dir)\n",
        "\n",
        "# Re-downloading NLTK data\n",
        "nltk.download('punkt', force=True)\n",
        "nltk.download('stopwords', force=True)\n",
        "\n",
        "# Stopwords configuration (customize as needed)\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# Add additional stopwords or words to remove\n",
        "custom_stop_words = {\n",
        "    'et', 'al', 'using', 'also', 'may', 'one', 'two', 'three',\n",
        "    'could', 'would', 'should', 'due', 'eg', 'ie', 'table', 'figure',\n",
        "    # Add patterns for numbers or years\n",
        "    *map(str, range(1900, 2030)),  # Exclude years (from 1900 to 2029)\n",
        "    '000', '00', '10', '20', '30', '40', '50', '60', '70', '80', '90',\n",
        "    # Other unnecessary words\n",
        "    'copyright', 'rights', 'reserved', 'http', 'doi', 'org', 'com', 'license', 'creativecommons', 'www','elsevier',\"basel\", \"karger\"\n",
        "}\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "# Importing libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "from gensim import corpora, models\n",
        "import pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "from openai import OpenAI  # OpenAI client\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from google.colab import files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.util import ngrams\n",
        "import PyPDF2\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "uyPyq7uNiBO_",
        "outputId": "2b1d91ad-e6a1-4ee3-a80d-fbe759a60d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分析したいExcelまたはCSVファイルをアップロードしてください。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79428e2f-0f85-4dc7-bcef-71967e86a534\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-79428e2f-0f85-4dc7-bcef-71967e86a534\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving scopus_1-4484_20250218_cleanup.csv to scopus_1-4484_20250218_cleanup.csv\n"
          ]
        }
      ],
      "source": [
        "# @title 2. File Upload\n",
        "# Step 1: File Upload\n",
        "print(\"Please upload the Excel or CSV file you wish to analyze.\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Data Loading\n",
        "if file_name.endswith('.csv'):\n",
        "    df = pd.read_csv(file_name)\n",
        "elif file_name.endswith('.xlsx'):\n",
        "    df = pd.read_excel(file_name)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported file format. Please upload a CSV or Excel file.\")\n",
        "\n",
        "# Check for the presence of 'Abstract' and 'Publication Year' columns\n",
        "if 'Abstract' not in df.columns or 'Publication Year' not in df.columns:\n",
        "    raise ValueError(\"The file must include the 'Abstract' column and the 'Publication Year' column.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mgcM8HgiOE7",
        "outputId": "c73a3848-4a80-4844-aa7f-1c821599433b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# @title 3. Text Preprocessing\n",
        "# Step 3: Text Preprocessing and Tokenization\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove hyperlinks and email addresses\n",
        "    text = re.sub(r'http\\S+|www\\S+|mailto:\\S+', '', text)\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenization\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    # Remove stopwords\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Replace NaN values with an empty string\n",
        "df['Abstract'] = df['Abstract'].fillna('')\n",
        "\n",
        "# Add tokenized text as a new column\n",
        "df['tokens'] = df['Abstract'].apply(preprocess_text)\n",
        "\n",
        "# Creating n-grams (bigrams and trigrams)\n",
        "def create_ngrams(tokens_list, n):\n",
        "    ngrams_list = list(ngrams(tokens_list, n))\n",
        "    ngrams_joined = ['_'.join(gram) for gram in ngrams_list]\n",
        "    return ngrams_joined\n",
        "\n",
        "# Add n-grams to the dataframe\n",
        "df['bigrams'] = df['tokens'].apply(lambda x: create_ngrams(x, 2))\n",
        "df['trigrams'] = df['tokens'].apply(lambda x: create_ngrams(x, 3))\n",
        "df['all_tokens'] = df['tokens'] + df['bigrams'] + df['trigrams']\n",
        "\n",
        "# Convert the 'Publication Year' column to integer type\n",
        "df['Publication Year'] = pd.to_numeric(df['Publication Year'], errors='coerce')\n",
        "df = df.dropna(subset=['Publication Year'])  # Drop rows where year is NaN\n",
        "df['Publication Year'] = df['Publication Year'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkrcqNFRl9az",
        "outputId": "d2e5ae4c-b3ac-4a5c-c436-f25e1be2e68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ユニグラム（単語）の分析 ===\n",
            "\n",
            "=== バイグラム（bigrams）の分析 ===\n",
            "\n",
            "=== トライグラム（trigrams）の分析 ===\n",
            "\n",
            "=== 各期間の頻出語トップ50（単語） ===\n",
            "\n",
            "期間: 2014-2016\n",
            "              word  count\n",
            "0        aflatoxin    985\n",
            "1          samples    881\n",
            "2              afb    843\n",
            "3             food    515\n",
            "4       mycotoxins    457\n",
            "5       aflatoxins    438\n",
            "6        detection    383\n",
            "7           levels    367\n",
            "8    contamination    363\n",
            "9            study    347\n",
            "10            milk    338\n",
            "11             gkg    318\n",
            "12             afm    316\n",
            "13          method    305\n",
            "14         results    288\n",
            "15        analysis    257\n",
            "16            used    252\n",
            "17       mycotoxin    235\n",
            "18    respectively    234\n",
            "19            feed    230\n",
            "20            high    227\n",
            "21           total    219\n",
            "22           maize    218\n",
            "23        exposure    218\n",
            "24     aspergillus    217\n",
            "25           found    205\n",
            "26             ota    203\n",
            "27        products    199\n",
            "28          flavus    197\n",
            "29       different    194\n",
            "30          showed    193\n",
            "31   concentration    192\n",
            "32           limit    188\n",
            "33          health    178\n",
            "34    contaminated    177\n",
            "35         methods    176\n",
            "36           based    174\n",
            "37      production    172\n",
            "38          fungal    171\n",
            "39          liquid    161\n",
            "40              kg    144\n",
            "41           range    144\n",
            "42  concentrations    144\n",
            "43           human    140\n",
            "44         effects    140\n",
            "45             afs    140\n",
            "46          growth    139\n",
            "47  chromatography    136\n",
            "48           level    135\n",
            "49        produced    134\n",
            "\n",
            "期間: 2017-2019\n",
            "              word  count\n",
            "0              afb   1907\n",
            "1        aflatoxin   1844\n",
            "2          samples   1463\n",
            "3       mycotoxins   1120\n",
            "4             food   1042\n",
            "5       aflatoxins    878\n",
            "6            study    793\n",
            "7        detection    770\n",
            "8    contamination    687\n",
            "9           levels    651\n",
            "10            feed    627\n",
            "11             gkg    603\n",
            "12         results    580\n",
            "13             afm    575\n",
            "14          method    572\n",
            "15            milk    556\n",
            "16    respectively    526\n",
            "17       mycotoxin    495\n",
            "18     aspergillus    494\n",
            "19          flavus    491\n",
            "20           maize    462\n",
            "21        analysis    457\n",
            "22          showed    436\n",
            "23        products    411\n",
            "24        exposure    408\n",
            "25            used    400\n",
            "26            high    399\n",
            "27          health    397\n",
            "28    contaminated    397\n",
            "29      production    379\n",
            "30          fungal    372\n",
            "31       different    369\n",
            "32           total    369\n",
            "33           found    361\n",
            "34          growth    338\n",
            "35   concentration    329\n",
            "36         effects    325\n",
            "37             ota    317\n",
            "38           range    310\n",
            "39           fungi    304\n",
            "40            risk    301\n",
            "41           group    300\n",
            "42           based    299\n",
            "43        detected    293\n",
            "44             afs    293\n",
            "45         control    288\n",
            "46  concentrations    284\n",
            "47       potential    277\n",
            "48           limit    273\n",
            "49       developed    270\n",
            "\n",
            "期間: 2020-2022\n",
            "              word  count\n",
            "0              afb   2292\n",
            "1        aflatoxin   2098\n",
            "2          samples   1973\n",
            "3             food   1713\n",
            "4       mycotoxins   1500\n",
            "5        detection   1187\n",
            "6       aflatoxins   1087\n",
            "7            study   1077\n",
            "8    contamination    919\n",
            "9           method    805\n",
            "10            feed    801\n",
            "11         results    787\n",
            "12          levels    775\n",
            "13            milk    767\n",
            "14             afm    754\n",
            "15          health    745\n",
            "16             gkg    700\n",
            "17        analysis    698\n",
            "18       mycotoxin    667\n",
            "19        exposure    663\n",
            "20    respectively    628\n",
            "21          flavus    607\n",
            "22         authors    580\n",
            "23     aspergillus    577\n",
            "24            used    576\n",
            "25          showed    564\n",
            "26            high    553\n",
            "27           total    537\n",
            "28            risk    535\n",
            "29        products    531\n",
            "30           maize    521\n",
            "31       different    498\n",
            "32             ota    488\n",
            "33      production    462\n",
            "34         control    459\n",
            "35          safety    446\n",
            "36         effects    444\n",
            "37    contaminated    441\n",
            "38         methods    441\n",
            "39           found    439\n",
            "40   concentration    419\n",
            "41           based    418\n",
            "42       potential    402\n",
            "43           group    395\n",
            "44           human    392\n",
            "45        detected    388\n",
            "46           limit    384\n",
            "47          fungal    384\n",
            "48  concentrations    368\n",
            "49          growth    360\n",
            "\n",
            "期間: 2023-2025\n",
            "             word  count\n",
            "0             afb   2322\n",
            "1       aflatoxin   1716\n",
            "2            food   1599\n",
            "3       detection   1377\n",
            "4         samples   1335\n",
            "5      mycotoxins   1108\n",
            "6           study   1019\n",
            "7      aflatoxins    787\n",
            "8   contamination    762\n",
            "9          health    690\n",
            "10         method    674\n",
            "11       analysis    664\n",
            "12        results    652\n",
            "13         levels    600\n",
            "14           feed    583\n",
            "15      mycotoxin    578\n",
            "16            gkg    569\n",
            "17         safety    535\n",
            "18           used    508\n",
            "19        authors    506\n",
            "20           milk    490\n",
            "21           high    489\n",
            "22         flavus    482\n",
            "23       products    475\n",
            "24        methods    464\n",
            "25   respectively    461\n",
            "26    aspergillus    455\n",
            "27       exposure    455\n",
            "28      potential    446\n",
            "29         showed    441\n",
            "30          maize    441\n",
            "31            afm    414\n",
            "32     production    411\n",
            "33    significant    411\n",
            "34           risk    396\n",
            "35          total    383\n",
            "36          based    363\n",
            "37          limit    359\n",
            "38  concentration    355\n",
            "39      different    353\n",
            "40        effects    351\n",
            "41        control    346\n",
            "42            ota    336\n",
            "43          found    334\n",
            "44          human    333\n",
            "45          range    320\n",
            "46            afs    319\n",
            "47  significantly    319\n",
            "48         fungal    318\n",
            "49      developed    317\n",
            "\n",
            "=== 各期間の頻出語トップ50（バイグラム） ===\n",
            "\n",
            "期間: 2014-2016\n",
            "                          word  count\n",
            "0                aflatoxin_afb    154\n",
            "1        liquid_chromatography    108\n",
            "2      aflatoxin_contamination     81\n",
            "3            mass_spectrometry     71\n",
            "4           aspergillus_flavus     71\n",
            "5                 milk_samples     67\n",
            "6                  food_safety     64\n",
            "7               taylor_francis     60\n",
            "8                        ng_ml     54\n",
            "9            samples_collected     52\n",
            "10                   food_feed     51\n",
            "11              ochratoxin_ota     50\n",
            "12             limit_detection     49\n",
            "13               aflatoxin_afm     47\n",
            "14     mycotoxin_contamination     46\n",
            "15             detection_limit     46\n",
            "16      highperformance_liquid     45\n",
            "17        aflatoxin_production     45\n",
            "18                    afm_milk     45\n",
            "19          performance_liquid     44\n",
            "20               licensee_mdpi     44\n",
            "21            mdpi_switzerland     44\n",
            "22              aflatoxins_afs     41\n",
            "23            authors_licensee     40\n",
            "24               present_study     40\n",
            "25                     afb_afb     40\n",
            "26            total_aflatoxins     38\n",
            "27            high_performance     37\n",
            "28              european_union     36\n",
            "29              results_showed     35\n",
            "30                     afb_afg     32\n",
            "31                     gkg_gkg     32\n",
            "32             total_aflatoxin     32\n",
            "33        samples_contaminated     32\n",
            "34                feed_samples     32\n",
            "35              dairy_products     31\n",
            "36            aflatoxin_levels     31\n",
            "37         aflatoxin_aflatoxin     30\n",
            "38         immunosorbent_assay     29\n",
            "39  enzymelinked_immunosorbent     29\n",
            "40               maize_samples     27\n",
            "41         chromatography_hplc     27\n",
            "42               fungal_growth     27\n",
            "43      fluorescence_detection     27\n",
            "44                     afg_afg     27\n",
            "45     aspergillus_parasiticus     26\n",
            "46            limits_detection     26\n",
            "47               food_products     26\n",
            "48                human_health     25\n",
            "49         detection_aflatoxin     25\n",
            "\n",
            "期間: 2017-2019\n",
            "                          word  count\n",
            "0                aflatoxin_afb    338\n",
            "1           aspergillus_flavus    189\n",
            "2        liquid_chromatography    157\n",
            "3                  food_safety    155\n",
            "4      aflatoxin_contamination    148\n",
            "5                licensee_mdpi    134\n",
            "6             mdpi_switzerland    134\n",
            "7            mass_spectrometry    132\n",
            "8             authors_licensee    130\n",
            "9                    food_feed    104\n",
            "10           samples_collected    101\n",
            "11               present_study    101\n",
            "12               aflatoxin_afm    101\n",
            "13                milk_samples     98\n",
            "14              ochratoxin_ota     94\n",
            "15              results_showed     91\n",
            "16     mycotoxin_contamination     89\n",
            "17              taylor_francis     88\n",
            "18               francis_group     86\n",
            "19       secondary_metabolites     82\n",
            "20        aflatoxin_production     80\n",
            "21                     afb_afb     79\n",
            "22                     gkg_gkg     76\n",
            "23             limit_detection     72\n",
            "24              aflatoxins_afs     70\n",
            "25                       ng_ml     70\n",
            "26             detection_limit     68\n",
            "27      highperformance_liquid     65\n",
            "28                human_health     64\n",
            "29          aflatoxin_exposure     64\n",
            "30                food_samples     62\n",
            "31                feed_samples     62\n",
            "32          performance_liquid     60\n",
            "33               detection_afb     59\n",
            "34         immunosorbent_assay     58\n",
            "35                 body_weight     57\n",
            "36  enzymelinked_immunosorbent     57\n",
            "37              european_union     55\n",
            "38                 study_aimed     55\n",
            "39        samples_contaminated     54\n",
            "40               food_products     54\n",
            "41               fungal_growth     54\n",
            "42             springer_nature     53\n",
            "43                     afb_afg     52\n",
            "44                 animal_feed     51\n",
            "45                   aim_study     50\n",
            "46                 tandem_mass     50\n",
            "47               section_flavi     49\n",
            "48     aspergillus_parasiticus     49\n",
            "49              dairy_products     49\n",
            "\n",
            "期間: 2020-2022\n",
            "                       word  count\n",
            "0             aflatoxin_afb    434\n",
            "1               food_safety    298\n",
            "2          authors_licensee    284\n",
            "3             licensee_mdpi    282\n",
            "4          mdpi_switzerland    282\n",
            "5     liquid_chromatography    244\n",
            "6        aspergillus_flavus    230\n",
            "7   aflatoxin_contamination    206\n",
            "8         mass_spectrometry    153\n",
            "9                 food_feed    150\n",
            "10            present_study    135\n",
            "11           ochratoxin_ota    134\n",
            "12           results_showed    132\n",
            "13             human_health    125\n",
            "14             milk_samples    123\n",
            "15   highperformance_liquid    117\n",
            "16          limit_detection    116\n",
            "17        samples_collected    116\n",
            "18            aflatoxin_afm    116\n",
            "19  mycotoxin_contamination    110\n",
            "20          detection_limit    108\n",
            "21            public_health    106\n",
            "22              study_aimed    105\n",
            "23                  afb_afb    104\n",
            "24    secondary_metabolites     99\n",
            "25            food_products     96\n",
            "26           aflatoxins_afs     95\n",
            "27                  afb_afg     91\n",
            "28            detection_afb     87\n",
            "29             food_samples     86\n",
            "30         total_aflatoxins     83\n",
            "31             daily_intake     82\n",
            "32     aflatoxin_production     81\n",
            "33              animal_feed     78\n",
            "34                    ng_ml     77\n",
            "35           taylor_francis     75\n",
            "36           dairy_products     74\n",
            "37             feed_samples     74\n",
            "38            afb_detection     73\n",
            "39            francis_group     72\n",
            "40          springer_nature     71\n",
            "41      immunosorbent_assay     69\n",
            "42              health_risk     69\n",
            "43                  afg_afg     69\n",
            "44      chromatography_hplc     68\n",
            "45              breast_milk     67\n",
            "46      detection_aflatoxin     66\n",
            "47          risk_assessment     65\n",
            "48     samples_contaminated     65\n",
            "49          zearalenone_zen     64\n",
            "\n",
            "期間: 2023-2025\n",
            "                       word  count\n",
            "0             aflatoxin_afb    422\n",
            "1               food_safety    359\n",
            "2        aspergillus_flavus    171\n",
            "3     liquid_chromatography    167\n",
            "4              human_health    154\n",
            "5   aflatoxin_contamination    149\n",
            "6           detection_limit    128\n",
            "7             detection_afb    119\n",
            "8         mass_spectrometry    118\n",
            "9   mycotoxin_contamination    113\n",
            "10                food_feed    113\n",
            "11            public_health    112\n",
            "12              study_aimed    106\n",
            "13           results_showed    103\n",
            "14            afb_detection     98\n",
            "15                    ng_ml     98\n",
            "16   highperformance_liquid     94\n",
            "17           ochratoxin_ota     94\n",
            "18          limit_detection     94\n",
            "19             milk_samples     87\n",
            "20           aflatoxins_afs     81\n",
            "21             health_risks     80\n",
            "22        samples_collected     78\n",
            "23            present_study     73\n",
            "24             food_samples     71\n",
            "25             linear_range     68\n",
            "26                  afb_afg     65\n",
            "27      detection_aflatoxin     65\n",
            "28    secondary_metabolites     65\n",
            "29              animal_feed     65\n",
            "30                  afb_afb     64\n",
            "31           humans_animals     62\n",
            "32        afb_contamination     62\n",
            "33     aflatoxin_production     61\n",
            "34      sensitive_detection     61\n",
            "35            aflatoxin_afm     60\n",
            "36         aflatoxin_levels     59\n",
            "37      multiple_mycotoxins     58\n",
            "38            detection_lod     58\n",
            "39              health_risk     56\n",
            "40          total_aflatoxin     55\n",
            "41                  gkg_gkg     55\n",
            "42           taylor_francis     54\n",
            "43      immunosorbent_assay     53\n",
            "44           dairy_products     53\n",
            "45          zearalenone_zen     53\n",
            "46            francis_group     52\n",
            "47         detection_limits     51\n",
            "48        detection_methods     51\n",
            "49     samples_contaminated     51\n",
            "\n",
            "=== 各期間の頻出語トップ50（トライグラム） ===\n",
            "\n",
            "期間: 2014-2016\n",
            "                                      word  count\n",
            "0                licensee_mdpi_switzerland     44\n",
            "1    highperformance_liquid_chromatography     42\n",
            "2                    authors_licensee_mdpi     40\n",
            "3                  high_performance_liquid     37\n",
            "4        performance_liquid_chromatography     37\n",
            "5               liquid_chromatography_hplc     27\n",
            "6         enzymelinked_immunosorbent_assay     26\n",
            "7                              afb_afb_afg     24\n",
            "8                              afb_afg_afg     24\n",
            "9                     taylor_francis_group     23\n",
            "10        springerverlag_berlin_heidelberg     22\n",
            "11                     limit_detection_lod     21\n",
            "12                tandem_mass_spectrometry     20\n",
            "13          wageningen_academic_publishers     20\n",
            "14                     milk_dairy_products     19\n",
            "15  chromatographytandem_mass_spectrometry     19\n",
            "16        liquid_chromatographytandem_mass     18\n",
            "17                food_drug_administration     17\n",
            "18                 aflatoxin_afb_aflatoxin     16\n",
            "19           liquid_chromatography_coupled     16\n",
            "20                      informa_uk_limited     15\n",
            "21                      uk_limited_trading     15\n",
            "22                  limited_trading_taylor     15\n",
            "23                  trading_taylor_francis     15\n",
            "24          aspergillus_flavus_aspergillus     15\n",
            "25          flavus_aspergillus_parasiticus     15\n",
            "26                 royal_society_chemistry     15\n",
            "27           aflatoxin_aflatoxin_aflatoxin     15\n",
            "28                    gkg_gkg_respectively     14\n",
            "29          secondary_metabolites_produced     14\n",
            "30                mass_spectrometry_lcmsms     12\n",
            "31               immunosorbent_assay_elisa     12\n",
            "32            liquid_chromatography_tandem     12\n",
            "33              chromatography_tandem_mass     12\n",
            "34                          afb_peanut_oil     11\n",
            "35                     human_animal_health     11\n",
            "36             growth_aflatoxin_production     11\n",
            "37                 detection_aflatoxin_afb     10\n",
            "38                             range_ng_ml     10\n",
            "39              society_mycotoxin_research     10\n",
            "40       mycotoxin_research_springerverlag     10\n",
            "41          research_springerverlag_berlin     10\n",
            "42                      aflatoxin_afm_milk     10\n",
            "43                  milk_samples_collected      9\n",
            "44               american_chemical_society      9\n",
            "45               thin_layer_chromatography      9\n",
            "46             produced_aspergillus_flavus      9\n",
            "47             method_successfully_applied      9\n",
            "48               aflatoxins_afs_ochratoxin      9\n",
            "49                      afs_ochratoxin_ota      9\n",
            "\n",
            "期間: 2017-2019\n",
            "                                      word  count\n",
            "0                licensee_mdpi_switzerland    134\n",
            "1                    authors_licensee_mdpi    130\n",
            "2                     taylor_francis_group     86\n",
            "3    highperformance_liquid_chromatography     57\n",
            "4         enzymelinked_immunosorbent_assay     52\n",
            "5        performance_liquid_chromatography     50\n",
            "6                     part_springer_nature     48\n",
            "7                   trading_taylor_francis     47\n",
            "8                 tandem_mass_spectrometry     46\n",
            "9                  high_performance_liquid     46\n",
            "10                      informa_uk_limited     46\n",
            "11                      uk_limited_trading     46\n",
            "12                  limited_trading_taylor     46\n",
            "13               aspergillus_section_flavi     42\n",
            "14        liquid_chromatographytandem_mass     42\n",
            "15  chromatographytandem_mass_spectrometry     42\n",
            "16                             afb_afb_afg     41\n",
            "17                       francis_group_llc     39\n",
            "18                             afb_afg_afg     39\n",
            "19               american_chemical_society     37\n",
            "20               society_chemical_industry     36\n",
            "21             springerverlag_gmbh_germany     32\n",
            "22                mass_spectrometry_lcmsms     32\n",
            "23          aspergillus_flavus_aspergillus     30\n",
            "24              liquid_chromatography_hplc     30\n",
            "25                     limit_detection_lod     30\n",
            "26           liquid_chromatography_coupled     29\n",
            "27               immunosorbent_assay_elisa     29\n",
            "28          wageningen_academic_publishers     29\n",
            "29                       gmbh_germany_part     27\n",
            "30                   germany_part_springer     27\n",
            "31                 detection_aflatoxin_afb     26\n",
            "32          flavus_aspergillus_parasiticus     26\n",
            "33              chromatography_tandem_mass     25\n",
            "34                     human_animal_health     25\n",
            "35      liquid_chromatography_fluorescence     24\n",
            "36          secondary_metabolites_produced     23\n",
            "37                 aflatoxin_afb_aflatoxin     23\n",
            "38            liquid_chromatography_tandem     23\n",
            "39             relative_standard_deviation     23\n",
            "40                    lactic_acid_bacteria     20\n",
            "41                 royal_society_chemistry     20\n",
            "42                    gkg_gkg_respectively     20\n",
            "43            relative_standard_deviations     19\n",
            "44              society_mycotoxin_research     19\n",
            "45                     milk_dairy_products     19\n",
            "46           aflatoxin_aflatoxin_aflatoxin     19\n",
            "47                  available_see_fulltext     18\n",
            "48            scanning_electron_microscopy     18\n",
            "49               chemical_industry_society     18\n",
            "\n",
            "期間: 2020-2022\n",
            "                                      word  count\n",
            "0                    authors_licensee_mdpi    282\n",
            "1                licensee_mdpi_switzerland    282\n",
            "2    highperformance_liquid_chromatography    109\n",
            "3                     taylor_francis_group     72\n",
            "4               liquid_chromatography_hplc     68\n",
            "5                              afb_afb_afg     68\n",
            "6                              afb_afg_afg     64\n",
            "7                     part_springer_nature     63\n",
            "8         enzymelinked_immunosorbent_assay     56\n",
            "9                 tandem_mass_spectrometry     56\n",
            "10                       francis_group_llc     54\n",
            "11       performance_liquid_chromatography     50\n",
            "12                     human_animal_health     48\n",
            "13           liquid_chromatography_coupled     43\n",
            "14                     limit_detection_lod     42\n",
            "15                     margin_exposure_moe     40\n",
            "16                     milk_dairy_products     39\n",
            "17        liquid_chromatographytandem_mass     39\n",
            "18          secondary_metabolites_produced     39\n",
            "19                     open_access_article     39\n",
            "20                 high_performance_liquid     38\n",
            "21  chromatographytandem_mass_spectrometry     38\n",
            "22            creative_commons_attribution     37\n",
            "23          wageningen_academic_publishers     37\n",
            "24                  estimated_daily_intake     36\n",
            "25          aspergillus_flavus_aspergillus     35\n",
            "26             springerverlag_gmbh_germany     35\n",
            "27                       gmbh_germany_part     35\n",
            "28                   germany_part_springer     35\n",
            "29              access_article_distributed     33\n",
            "30               article_distributed_terms     33\n",
            "31                    lactic_acid_bacteria     33\n",
            "32               american_chemical_society     32\n",
            "33      liquid_chromatography_fluorescence     32\n",
            "34               immunosorbent_assay_elisa     31\n",
            "35                 detection_aflatoxin_afb     31\n",
            "36               authors_exclusive_licence     30\n",
            "37               aspergillus_section_flavi     30\n",
            "38                aflatoxin_afb_ochratoxin     26\n",
            "39                        daily_intake_edi     26\n",
            "40            scanning_electron_microscopy     25\n",
            "41                      afb_ochratoxin_ota     24\n",
            "42                      aflatoxins_afb_afb     24\n",
            "43                     article_open_access     24\n",
            "44               terms_conditions_creative     24\n",
            "45             conditions_creative_commons     24\n",
            "46              ochratoxin_ota_zearalenone     23\n",
            "47            relative_standard_deviations     23\n",
            "48                     coupled_tandem_mass     23\n",
            "49            distributed_terms_conditions     23\n",
            "\n",
            "期間: 2023-2025\n",
            "                                      word  count\n",
            "0    highperformance_liquid_chromatography     89\n",
            "1                     taylor_francis_group     52\n",
            "2                      limit_detection_lod     51\n",
            "3               liquid_chromatography_hplc     48\n",
            "4                authors_exclusive_licence     48\n",
            "5         enzymelinked_immunosorbent_assay     43\n",
            "6                  detection_aflatoxin_afb     39\n",
            "7                     part_springer_nature     39\n",
            "8                american_chemical_society     39\n",
            "9                              afb_afb_afg     37\n",
            "10                             afb_afg_afg     37\n",
            "11        liquid_chromatographytandem_mass     36\n",
            "12  chromatographytandem_mass_spectrometry     36\n",
            "13                             range_ng_ml     36\n",
            "14                     low_detection_limit     31\n",
            "15                       francis_group_llc     30\n",
            "16                     human_animal_health     29\n",
            "17           liquid_chromatography_coupled     29\n",
            "18                tandem_mass_spectrometry     28\n",
            "19               immunosorbent_assay_elisa     27\n",
            "20       performance_liquid_chromatography     27\n",
            "21          aspergillus_flavus_aspergillus     27\n",
            "22                 high_performance_liquid     25\n",
            "23                 sensitive_detection_afb     23\n",
            "24                      afb_ochratoxin_ota     23\n",
            "25            scanning_electron_microscopy     22\n",
            "26                     threat_human_health     22\n",
            "27                aflatoxin_afb_ochratoxin     22\n",
            "28                      informa_uk_limited     22\n",
            "29                      uk_limited_trading     22\n",
            "30                  limited_trading_taylor     22\n",
            "31                  trading_taylor_francis     22\n",
            "32             relative_standard_deviation     21\n",
            "33                     margin_exposure_moe     21\n",
            "34                mass_spectrometry_lcmsms     21\n",
            "35             aflatoxin_afb_contamination     21\n",
            "36               aflatoxin_afb_zearalenone     21\n",
            "37              exclusive_licence_springer     21\n",
            "38          secondary_metabolites_produced     21\n",
            "39             toxic_secondary_metabolites     21\n",
            "40                       food_safety_human     20\n",
            "41                     safety_human_health     20\n",
            "42                    gkg_gkg_respectively     20\n",
            "43                    lactic_acid_bacteria     19\n",
            "44                     milk_dairy_products     19\n",
            "45                  potential_health_risks     19\n",
            "46            relative_standard_deviations     19\n",
            "47                     afb_zearalenone_zen     19\n",
            "48               aspergillus_section_flavi     18\n",
            "49             produced_aspergillus_flavus     18\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Specify the Time Periods for Analysis\n",
        "periods = [ '2014-2016', '2017-2019', '2020-2022', '2023-2025']\n",
        "period_ranges = {\n",
        "    '2014-2016': (2014, 2016),\n",
        "    '2017-2019': (2017, 2019),\n",
        "    '2020-2022': (2020, 2022),\n",
        "    '2023-2025': (2023, 2025)\n",
        "}\n",
        "\n",
        "# Add a 'period' column based on 'Publication Year'\n",
        "def assign_period(year):\n",
        "    for period, (start, end) in period_ranges.items():\n",
        "        if start <= year <= end:\n",
        "            return period\n",
        "    return None  # If not applicable\n",
        "\n",
        "df['period'] = df['Publication Year'].apply(assign_period)\n",
        "\n",
        "# Drop rows where 'period' is None\n",
        "df = df.dropna(subset=['period'])\n",
        "\n",
        "# @title 4. Analysis of Frequent Words\n",
        "# Step 5: Analyze frequent words and calculate new terms and terms with high growth rates\n",
        "\n",
        "def analyze_terms(df, token_column):\n",
        "    # Obtain the list of periods (sorted order)\n",
        "    periods_sorted = sorted(df['period'].unique(), key=lambda x: period_ranges[x][0])\n",
        "\n",
        "    # Create a dictionary to store tokenized data for each period\n",
        "    period_tokens = {}\n",
        "    for period in periods_sorted:\n",
        "        period_df = df[df['period'] == period]\n",
        "        tokens_list = period_df[token_column].tolist()\n",
        "        period_tokens[period] = tokens_list\n",
        "\n",
        "    # Calculate frequency for each period\n",
        "    freq_by_period = {}\n",
        "    for period in periods_sorted:\n",
        "        all_tokens = [token for tokens in period_tokens[period] for token in tokens]\n",
        "        freq_by_period[period] = Counter(all_tokens)\n",
        "\n",
        "    # Store the top 50 frequent words for each period in a dataframe\n",
        "    all_data = {}\n",
        "    for period in periods_sorted:\n",
        "        common_terms = freq_by_period[period].most_common(50)\n",
        "        df_common = pd.DataFrame(common_terms, columns=['word', 'count'])\n",
        "        all_data[period] = df_common\n",
        "\n",
        "    # Calculate new terms for each period\n",
        "    new_terms = {}\n",
        "    previous_terms = set()\n",
        "    for period in periods_sorted:\n",
        "        current_terms = set(freq_by_period[period].keys())\n",
        "        new_terms_in_period = current_terms - previous_terms\n",
        "        new_terms[period] = new_terms_in_period\n",
        "        previous_terms.update(current_terms)\n",
        "\n",
        "    # Extract terms with high growth rates\n",
        "    growth_terms = {}\n",
        "    growth_rates = {}\n",
        "    growth_counts = {}\n",
        "\n",
        "    for i in range(1, len(periods_sorted)):\n",
        "        current_period = periods_sorted[i]\n",
        "        previous_period = periods_sorted[i-1]\n",
        "        current_freq = freq_by_period[current_period]\n",
        "        previous_freq = freq_by_period[previous_period]\n",
        "        common_terms = set(current_freq.keys()) & set(previous_freq.keys())\n",
        "        growth = {}\n",
        "        counts = {}\n",
        "        for term in common_terms:\n",
        "            prev_count = previous_freq.get(term, 0)\n",
        "            curr_count = current_freq.get(term, 0)\n",
        "            if prev_count > 0:\n",
        "                rate = ((curr_count - prev_count) / prev_count) * 100  # Convert to percentage\n",
        "                growth[term] = rate\n",
        "                counts[term] = curr_count  # Save frequency count\n",
        "        # Sort in descending order of growth rate and extract top N\n",
        "        top_n = 50  # Change as needed\n",
        "        sorted_growth = sorted(growth.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_terms = sorted_growth[:top_n]\n",
        "        growth_terms[current_period] = [term for term, rate in top_terms]\n",
        "        growth_rates[current_period] = {term: rate for term, rate in top_terms}\n",
        "        growth_counts[current_period] = {term: counts[term] for term, _ in top_terms}\n",
        "\n",
        "    return all_data, new_terms, growth_terms, growth_rates, growth_counts, freq_by_period\n",
        "\n",
        "# Unigram Analysis\n",
        "print(\"\\n=== Analysis of Unigrams (words) ===\")\n",
        "uni_all_data, uni_new_terms, uni_growth_terms, uni_growth_rates, uni_growth_counts, uni_freq_by_period = analyze_terms(df, 'tokens')\n",
        "\n",
        "# Bigram Analysis\n",
        "print(\"\\n=== Analysis of Bigrams ===\")\n",
        "bi_all_data, bi_new_terms, bi_growth_terms, bi_growth_rates, bi_growth_counts, bi_freq_by_period = analyze_terms(df, 'bigrams')\n",
        "\n",
        "# Trigram Analysis\n",
        "print(\"\\n=== Analysis of Trigrams ===\")\n",
        "tri_all_data, tri_new_terms, tri_growth_terms, tri_growth_rates, tri_growth_counts, tri_freq_by_period = analyze_terms(df, 'trigrams')\n",
        "\n",
        "# Step 5.5: Displaying Results\n",
        "\n",
        "# Display top 50 frequent unigrams for each period\n",
        "print(\"\\n=== Top 50 Frequent Unigrams for Each Period ===\")\n",
        "for period, df_common in uni_all_data.items():\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_common[['word', 'count']])\n",
        "\n",
        "# Display top 50 frequent bigrams for each period\n",
        "print(\"\\n=== Top 50 Frequent Bigrams for Each Period ===\")\n",
        "for period, df_common in bi_all_data.items():\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_common[['word', 'count']])\n",
        "\n",
        "# Display top 50 frequent trigrams for each period\n",
        "print(\"\\n=== Top 50 Frequent Trigrams for Each Period ===\")\n",
        "for period, df_common in tri_all_data.items():\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_common[['word', 'count']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UKkJ127l_1y",
        "outputId": "70909b20-75cf-4310-e2a9-018fe323d1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 新規出現語トップ50（単語） ===\n",
            "\n",
            "期間: 2014-2016\n",
            "                word  count\n",
            "922        aflatoxin    985\n",
            "6602         samples    881\n",
            "3071             afb    843\n",
            "6306            food    515\n",
            "4552      mycotoxins    457\n",
            "3570      aflatoxins    438\n",
            "1111       detection    383\n",
            "7058          levels    367\n",
            "7645   contamination    363\n",
            "8690           study    347\n",
            "2181            milk    338\n",
            "2411             gkg    318\n",
            "6900             afm    316\n",
            "4768          method    305\n",
            "719          results    288\n",
            "6594        analysis    257\n",
            "3204            used    252\n",
            "2837       mycotoxin    235\n",
            "5111    respectively    234\n",
            "8450            feed    230\n",
            "7431            high    227\n",
            "2525           total    219\n",
            "8277        exposure    218\n",
            "1070           maize    218\n",
            "303      aspergillus    217\n",
            "4501           found    205\n",
            "8092             ota    203\n",
            "7485        products    199\n",
            "8888          flavus    197\n",
            "59         different    194\n",
            "6399          showed    193\n",
            "2693   concentration    192\n",
            "4719           limit    188\n",
            "8820          health    178\n",
            "2961    contaminated    177\n",
            "297          methods    176\n",
            "8213           based    174\n",
            "4342      production    172\n",
            "3673          fungal    171\n",
            "6156          liquid    161\n",
            "3312              kg    144\n",
            "1183           range    144\n",
            "3914  concentrations    144\n",
            "6103         effects    140\n",
            "4752             afs    140\n",
            "1264           human    140\n",
            "8826          growth    139\n",
            "89    chromatography    136\n",
            "1762           level    135\n",
            "8762        produced    134\n",
            "\n",
            "期間: 2017-2019\n",
            "                 word  count\n",
            "3229              cpa     34\n",
            "3328              cfs     33\n",
            "3215              eos     26\n",
            "1845             meju     23\n",
            "3017         drycured     22\n",
            "393           markers     21\n",
            "987        proportion     20\n",
            "7512    physiological     20\n",
            "1559           donkey     19\n",
            "5765              pre     19\n",
            "5888            malts     19\n",
            "3893               sb     18\n",
            "5088          chilies     18\n",
            "6293          oxidase     18\n",
            "820               cap     18\n",
            "3637     manufactures     17\n",
            "5062               oh     17\n",
            "4611          mutants     17\n",
            "5302            beers     17\n",
            "5552        buckwheat     17\n",
            "6613            iraqi     17\n",
            "2716          makueni     17\n",
            "1345              gst     16\n",
            "6389         ascorbic     16\n",
            "3503             cdna     16\n",
            "3015               nz     16\n",
            "4475           regard     16\n",
            "6139              adg     16\n",
            "6089              ecl     16\n",
            "7352       microbiome     15\n",
            "544              hccs     15\n",
            "2091             sdpp     15\n",
            "4150        southeast     15\n",
            "2239               lb     15\n",
            "851         beverages     15\n",
            "1836     inflammatory     14\n",
            "3257           family     14\n",
            "5351              ctb     14\n",
            "2062     photocurrent     14\n",
            "5284            cocoa     14\n",
            "6448               pc     14\n",
            "1713       hectolitre     13\n",
            "6490           colour     13\n",
            "4219               va     13\n",
            "4705               ge     13\n",
            "1362               wt     13\n",
            "3708  multimycotoxins     13\n",
            "1994            nandi     13\n",
            "64            austria     13\n",
            "7197         doenjang     13\n",
            "\n",
            "期間: 2020-2022\n",
            "                  word  count\n",
            "4971               res     22\n",
            "5817              mfeo     17\n",
            "613                apt     17\n",
            "2449           aflatfa     16\n",
            "1408              pycw     14\n",
            "185            aflatfb     14\n",
            "2070             camel     14\n",
            "3388              xchd     14\n",
            "4278          chesenps     13\n",
            "5445              fbgo     13\n",
            "1612               amk     13\n",
            "6636               gsm     13\n",
            "4219             colic     13\n",
            "1002         ustiloxin     13\n",
            "321               mceo     13\n",
            "6946              jute     13\n",
            "880                eps     12\n",
            "5404         zebrafish     12\n",
            "5766         lipolytic     12\n",
            "5571               hpp     12\n",
            "2439          cannabis     12\n",
            "4581              lsts     12\n",
            "1667               bap     12\n",
            "2783            stover     12\n",
            "249               maps     11\n",
            "5520  moldcontaminated     11\n",
            "6586             apple     11\n",
            "5661              bpeo     11\n",
            "1551          workflow     11\n",
            "927    chlorophyllides     11\n",
            "5322          plantain     11\n",
            "7478               cuo     11\n",
            "7224                hp     10\n",
            "361          irrigated     10\n",
            "3158              sowa     10\n",
            "4837             inner     10\n",
            "4595               peo     10\n",
            "4751               aac     10\n",
            "895              basin     10\n",
            "4402       selfpowered     10\n",
            "6485          promotes     10\n",
            "5481          electric     10\n",
            "1541              chia     10\n",
            "6481         prolifera     10\n",
            "6323              cceo     10\n",
            "910                gsa     10\n",
            "666              titer      9\n",
            "234           soumbala      9\n",
            "1336       bambusicola      9\n",
            "4625                zg      9\n",
            "\n",
            "期間: 2023-2025\n",
            "             word  count\n",
            "4591          bpa     21\n",
            "1371           az     20\n",
            "4915      biochar     19\n",
            "540         auncs     16\n",
            "762      nanopore     14\n",
            "5102   microalgae     14\n",
            "614         rinck     14\n",
            "3350         pedv     13\n",
            "3967          lbw     13\n",
            "5092         skru     13\n",
            "5909          ahr     13\n",
            "1191    berberine     12\n",
            "95        colitis     12\n",
            "5484         lacw     12\n",
            "4411          shb     11\n",
            "3468        pcpcf     11\n",
            "971           ala     10\n",
            "5419   birnessite     10\n",
            "2109   crisprcasa     10\n",
            "1417          dhm     10\n",
            "5536         hmpo     10\n",
            "4649         domw     10\n",
            "6137     abriifbi     10\n",
            "2762          zif      9\n",
            "482         cheka      9\n",
            "897          hsca      9\n",
            "2684         cseo      9\n",
            "3722          bfe      9\n",
            "2272   endophytes      9\n",
            "887          zena      9\n",
            "5474  sovereignty      9\n",
            "5476        peony      9\n",
            "4712         fhrb      9\n",
            "5878      berbere      9\n",
            "2983        pfago      9\n",
            "4102          pfw      9\n",
            "106   tolfenpyrad      9\n",
            "4608      phytase      8\n",
            "3995          wmw      8\n",
            "4862          enr      8\n",
            "2453   herbicides      8\n",
            "5492     biobased      8\n",
            "4416       aflavb      8\n",
            "1682       arecae      8\n",
            "13            smp      8\n",
            "4951        sfwmr      8\n",
            "4974          gus      8\n",
            "2068        qhswa      8\n",
            "1886         ghsa      8\n",
            "1786     notified      8\n",
            "\n",
            "=== 新規出現語トップ50（バイグラム） ===\n",
            "\n",
            "期間: 2014-2016\n",
            "                             word  count\n",
            "42228               aflatoxin_afb    154\n",
            "33620       liquid_chromatography    108\n",
            "25121     aflatoxin_contamination     81\n",
            "12956          aspergillus_flavus     71\n",
            "18489           mass_spectrometry     71\n",
            "20721                milk_samples     67\n",
            "45513                 food_safety     64\n",
            "29059              taylor_francis     60\n",
            "41884                       ng_ml     54\n",
            "12105           samples_collected     52\n",
            "36397                   food_feed     51\n",
            "3318               ochratoxin_ota     50\n",
            "18314             limit_detection     49\n",
            "8120                aflatoxin_afm     47\n",
            "11887     mycotoxin_contamination     46\n",
            "22331             detection_limit     46\n",
            "6393         aflatoxin_production     45\n",
            "42264      highperformance_liquid     45\n",
            "9806                     afm_milk     45\n",
            "37461            mdpi_switzerland     44\n",
            "4485                licensee_mdpi     44\n",
            "48748          performance_liquid     44\n",
            "34102              aflatoxins_afs     41\n",
            "10424                     afb_afb     40\n",
            "4676                present_study     40\n",
            "21247            authors_licensee     40\n",
            "7192             total_aflatoxins     38\n",
            "9459             high_performance     37\n",
            "17707              european_union     36\n",
            "5383               results_showed     35\n",
            "11007                feed_samples     32\n",
            "17097                     afb_afg     32\n",
            "40188                     gkg_gkg     32\n",
            "19684             total_aflatoxin     32\n",
            "4960         samples_contaminated     32\n",
            "31347              dairy_products     31\n",
            "34056            aflatoxin_levels     31\n",
            "1831          aflatoxin_aflatoxin     30\n",
            "29209         immunosorbent_assay     29\n",
            "1925   enzymelinked_immunosorbent     29\n",
            "13141         chromatography_hplc     27\n",
            "10422      fluorescence_detection     27\n",
            "16683                     afg_afg     27\n",
            "48294               maize_samples     27\n",
            "6400                fungal_growth     27\n",
            "38822     aspergillus_parasiticus     26\n",
            "32391            limits_detection     26\n",
            "22960               food_products     26\n",
            "46221         detection_aflatoxin     25\n",
            "14264           afb_contamination     25\n",
            "\n",
            "期間: 2017-2019\n",
            "                         word  count\n",
            "39159         springer_nature     53\n",
            "15022           part_springer     48\n",
            "15301     springerverlag_gmbh     44\n",
            "22416            gmbh_germany     32\n",
            "32895            germany_part     27\n",
            "51413           ascorbic_acid     16\n",
            "64673                 afm_ota     16\n",
            "22109       aimed_investigate     15\n",
            "56159         incidence_range     15\n",
            "25642         pre_postharvest     15\n",
            "62136     packaging_materials     14\n",
            "36770                fish_fed     14\n",
            "75744      aoac_international     14\n",
            "59675           south_african     14\n",
            "73469             donkey_milk     13\n",
            "7175            aptamer_probe     13\n",
            "68290                log_cfug     13\n",
            "10376                fish_oil     12\n",
            "21085            austria_part     12\n",
            "34795            gmbh_austria     12\n",
            "37315     fusarium_mycotoxins     12\n",
            "33447       hectolitre_weight     12\n",
            "48027               cfs_lpmys     12\n",
            "11475                days_age     12\n",
            "23631          aflatoxin_risk     12\n",
            "61834               media_llc     11\n",
            "643           low_temperature     11\n",
            "5940      experimental_groups     11\n",
            "66578                 coli_oh     11\n",
            "9502       experimental_group     11\n",
            "43930      samples_mycotoxins     11\n",
            "7806     cellfree_supernatant     11\n",
            "68008    iranian_manufactures     11\n",
            "6794             meju_samples     10\n",
            "66200   commission_regulation     10\n",
            "43879       differences_among     10\n",
            "65016            addition_afb     10\n",
            "51938           maize_peanuts     10\n",
            "34915   production_aflatoxins     10\n",
            "44416             raw_peanuts     10\n",
            "30030       contaminated_diet     10\n",
            "51878       target_mycotoxins     10\n",
            "57972       metabolites_fungi     10\n",
            "63596                 ppb_ppb      9\n",
            "74201            afb_toxicity      9\n",
            "4677                  ng_afml      9\n",
            "34300               test_line      9\n",
            "31001  zearalenone_fumonisins      9\n",
            "3424                rrna_gene      9\n",
            "80284      afb_deoxynivalenol      9\n",
            "\n",
            "期間: 2020-2022\n",
            "                              word  count\n",
            "15821            authors_exclusive     30\n",
            "85965            exclusive_licence     30\n",
            "45348             licence_springer     18\n",
            "92595              periodicals_llc     17\n",
            "24533             acidophilus_atcc     16\n",
            "70130   electrochemical_biosensors     16\n",
            "97462               molitor_larvae     13\n",
            "61930               lb_acidophilus     13\n",
            "14000                wileyvch_gmbh     13\n",
            "32796                     dark_tea     12\n",
            "82324        chitosan_nanoemulsion     12\n",
            "72170              detection_rates     11\n",
            "68270               pistachio_nuts     11\n",
            "39264              direct_analysis     11\n",
            "16285            bambara_groundnut     10\n",
            "69292          contamination_lipid     10\n",
            "98158                    jute_bags     10\n",
            "18618             machine_learning     10\n",
            "63511            prolifera_extract      9\n",
            "28546                  ratio_range      9\n",
            "78666                   chia_seeds      9\n",
            "75610                     pgml_gkg      9\n",
            "64217   environmental_contaminants      9\n",
            "3886                positive_ratio      9\n",
            "10763          fungal_contaminants      9\n",
            "26836                 aft_exposure      9\n",
            "79922             health_challenge      8\n",
            "10932            food_preservative      8\n",
            "56499                cell_membrane      8\n",
            "126         licence_springerverlag      8\n",
            "73860               aptamer_sensor      8\n",
            "17508           aflatoxins_aftotal      8\n",
            "93733                 nutmeg_seeds      8\n",
            "71471            rainfed_irrigated      8\n",
            "16943              foods_beverages      8\n",
            "68214           sodium_bicarbonate      8\n",
            "58511                concern_study      8\n",
            "66078     lactobacillus_salivarius      8\n",
            "93748                    res_group      7\n",
            "11584         amyloliquefaciens_wf      7\n",
            "52477           storage_processing      7\n",
            "45494       chitosan_nanoparticles      7\n",
            "78617                        cu_zn      7\n",
            "42006       national_international      7\n",
            "6383                    goats_feed      7\n",
            "71855                      mno_nps      7\n",
            "70128                       ld_lkg      7\n",
            "76256              irrigated_zones      7\n",
            "102250                  grain_corn      7\n",
            "80080             typeb_aflatoxins      7\n",
            "\n",
            "期間: 2023-2025\n",
            "                              word  count\n",
            "8112             meat_alternatives     12\n",
            "148                   cat_activity     11\n",
            "68034                      feo_nps     11\n",
            "57464               organic_iodine     10\n",
            "15139                    goat_meat     10\n",
            "79181           posing_significant     10\n",
            "73775                  subtilis_zj     10\n",
            "17286                       ppm_la      9\n",
            "20682                    gp_served      9\n",
            "34469                 double_scale      9\n",
            "45392             aptasensing_chip      9\n",
            "59534          veterinary_research      9\n",
            "17030             food_sovereignty      9\n",
            "74454                     group_gp      8\n",
            "47225               berbere_powder      8\n",
            "73607                    bee_bread      8\n",
            "34975                 dna_hydrogel      8\n",
            "13981                 arecae_semen      8\n",
            "14475           abstract_presented      8\n",
            "57848                    served_af      8\n",
            "35271                 weak_binding      7\n",
            "15633              products_posing      7\n",
            "42507             ketobutyric_acid      7\n",
            "3703                         kg_ww      7\n",
            "39540             intestinal_flora      7\n",
            "180               republic_armenia      7\n",
            "82314                flour_berbere      7\n",
            "11980                   faecium_hb      7\n",
            "11986                        sn_kg      7\n",
            "35146                  shiro_flour      7\n",
            "47370                  median_ngml      7\n",
            "34545          antimycotoxin_agent      7\n",
            "34141              plantbased_meat      7\n",
            "77234                        la_la      7\n",
            "75263                     hgs_bags      7\n",
            "9572               hybrid_membrane      6\n",
            "42185                cerevisiae_nj      6\n",
            "64425          excellent_detection      6\n",
            "78858              detected_median      6\n",
            "27581             zongye_essential      6\n",
            "77884  algoclaybased_decontaminant      6\n",
            "9547             pericarpium_citri      6\n",
            "34718             ngml_furthermore      6\n",
            "12178               presents_novel      6\n",
            "5283                 associated_ci      6\n",
            "29354            sers_fluorescence      6\n",
            "33439                   peony_seed      6\n",
            "84629                 poses_severe      6\n",
            "77945          promising_prospects      6\n",
            "77750                      upp_oil      6\n",
            "\n",
            "=== 新規出現語トップ50（トライグラム） ===\n",
            "\n",
            "期間: 2014-2016\n",
            "                                         word  count\n",
            "21990               licensee_mdpi_switzerland     44\n",
            "14233   highperformance_liquid_chromatography     42\n",
            "29295                   authors_licensee_mdpi     40\n",
            "43510                 high_performance_liquid     37\n",
            "42517       performance_liquid_chromatography     37\n",
            "60493              liquid_chromatography_hplc     27\n",
            "56327        enzymelinked_immunosorbent_assay     26\n",
            "16213                             afb_afb_afg     24\n",
            "8103                              afb_afg_afg     24\n",
            "38021                    taylor_francis_group     23\n",
            "15234        springerverlag_berlin_heidelberg     22\n",
            "44403                     limit_detection_lod     21\n",
            "46565                tandem_mass_spectrometry     20\n",
            "28778          wageningen_academic_publishers     20\n",
            "36172                     milk_dairy_products     19\n",
            "36305  chromatographytandem_mass_spectrometry     19\n",
            "49649        liquid_chromatographytandem_mass     18\n",
            "18046                food_drug_administration     17\n",
            "1003                  aflatoxin_afb_aflatoxin     16\n",
            "11735           liquid_chromatography_coupled     16\n",
            "58443                      uk_limited_trading     15\n",
            "30097          flavus_aspergillus_parasiticus     15\n",
            "16277           aflatoxin_aflatoxin_aflatoxin     15\n",
            "13160                      informa_uk_limited     15\n",
            "55283                  trading_taylor_francis     15\n",
            "32729          aspergillus_flavus_aspergillus     15\n",
            "24939                 royal_society_chemistry     15\n",
            "59313                  limited_trading_taylor     15\n",
            "27661          secondary_metabolites_produced     14\n",
            "60230                    gkg_gkg_respectively     14\n",
            "6527             liquid_chromatography_tandem     12\n",
            "47415                mass_spectrometry_lcmsms     12\n",
            "19275              chromatography_tandem_mass     12\n",
            "54790               immunosorbent_assay_elisa     12\n",
            "17433                     human_animal_health     11\n",
            "31806             growth_aflatoxin_production     11\n",
            "55262                          afb_peanut_oil     11\n",
            "35539                      aflatoxin_afm_milk     10\n",
            "50524          research_springerverlag_berlin     10\n",
            "8031                  detection_aflatoxin_afb     10\n",
            "12666              society_mycotoxin_research     10\n",
            "2625        mycotoxin_research_springerverlag     10\n",
            "3564                              range_ng_ml     10\n",
            "802               produced_aspergillus_flavus      9\n",
            "51939               society_chemical_industry      9\n",
            "54056                      afs_ochratoxin_ota      9\n",
            "30591                  milk_samples_collected      9\n",
            "55603             method_successfully_applied      9\n",
            "27199               thin_layer_chromatography      9\n",
            "47947               american_chemical_society      9\n",
            "\n",
            "期間: 2017-2019\n",
            "                                       word  count\n",
            "25588                  part_springer_nature     48\n",
            "94054           springerverlag_gmbh_germany     32\n",
            "53326                     gmbh_germany_part     27\n",
            "69325                 germany_part_springer     27\n",
            "56781          fulltext_springerverlag_gmbh     16\n",
            "42871                    incidence_range_gl     14\n",
            "51114               study_aimed_investigate     14\n",
            "54239                effects_humans_animals     13\n",
            "32300                     gmbh_austria_part     12\n",
            "107116          springerverlag_gmbh_austria     12\n",
            "73495                 austria_part_springer     12\n",
            "72109             sciencebusiness_media_llc     11\n",
            "10811              aflatoxin_afm_ochratoxin      9\n",
            "74563           secondary_metabolites_fungi      9\n",
            "100027         research_springerverlag_gmbh      9\n",
            "119184                       media_llc_part      8\n",
            "69406               fumonisin_fb_ochratoxin      8\n",
            "45713                   quechers_quick_easy      8\n",
            "4194                       food_animal_feed      8\n",
            "107291                    gkg_aflatoxin_gkg      8\n",
            "30606                     llc_part_springer      8\n",
            "34940            makueni_nandi_respectively      7\n",
            "121372                    oxidized_fish_oil      7\n",
            "69690   aspergillus_parasiticus_aspergillus      7\n",
            "24290                       aflr_afls_genes      7\n",
            "35691                drycured_meat_products      7\n",
            "25480          aflatoxin_afb_deoxynivalenol      7\n",
            "51912         significant_differences_among      7\n",
            "43634                exceeded_maximum_level      7\n",
            "42134                           feed_afb_kg      7\n",
            "76001        samples_contaminated_aflatoxin      7\n",
            "15444                         afb_mgkg_zncm      7\n",
            "717                 milled_groundnut_powder      6\n",
            "108933                 fed_afb_contaminated      6\n",
            "16017    carcinogenic_secondary_metabolites      6\n",
            "85839          peanuts_peanutbased_products      6\n",
            "113779                afb_contaminated_diet      6\n",
            "117796              safety_authors_licensee      6\n",
            "8544                  serrata_essential_oil      6\n",
            "98900      mycotoxins_aflatoxins_ochratoxin      6\n",
            "58411      sporulation_aflatoxin_production      6\n",
            "30042                 public_health_problem      6\n",
            "56161                 low_hectolitre_weight      6\n",
            "80130        supercritical_fluid_extraction      6\n",
            "85755                toxin_detected_samples      6\n",
            "21647                high_hectolitre_weight      6\n",
            "58626                     black_soldier_fly      6\n",
            "113057                    risk_human_health      6\n",
            "34496                afb_contaminated_diets      6\n",
            "120806          mainly_produced_aspergillus      6\n",
            "\n",
            "期間: 2020-2022\n",
            "                                      word  count\n",
            "35359            authors_exclusive_licence     30\n",
            "161152          exclusive_licence_springer     18\n",
            "106052               wiley_periodicals_llc     17\n",
            "9635                   lb_acidophilus_atcc     13\n",
            "151449    licence_springer_sciencebusiness     12\n",
            "140604                     ratio_range_gkg      9\n",
            "23553                 positive_ratio_range      9\n",
            "130625    contamination_lipid_peroxidation      9\n",
            "11537          licence_springerverlag_gmbh      8\n",
            "75509     exclusive_licence_springerverlag      8\n",
            "113085              human_health_therefore      8\n",
            "130646            total_aflatoxins_aftotal      8\n",
            "91520                    major_food_safety      8\n",
            "60834               safety_hygiene_control      7\n",
            "2949                 exposure_moe_approach      7\n",
            "149289             rainfed_irrigated_zones      7\n",
            "11928               section_flavi_isolates      7\n",
            "65842          improved_growth_performance      6\n",
            "141869             licence_springer_nature      6\n",
            "6664                 aflatoxin_mgkg_groups      6\n",
            "103858              feeds_feed_ingredients      6\n",
            "131927           concentrations_ranging_gl      6\n",
            "46047                 exposure_afm_infants      6\n",
            "118892             afb_contamination_lipid      6\n",
            "130378                 serious_threat_food      6\n",
            "6997          contained_afm_concentrations      6\n",
            "66313                 detect_aflatoxin_afb      6\n",
            "91053     polycyclic_aromatic_hydrocarbons      6\n",
            "100557                          afb_ota_fb      6\n",
            "76736                 see_fulltext_authors      6\n",
            "57131   antiaflatoxigenic_mechanism_action      6\n",
            "121890                   intake_edi_margin      6\n",
            "45085                  edi_margin_exposure      6\n",
            "86958            infants_toddlers_children      6\n",
            "34234            hygiene_control_practices      6\n",
            "47778               periodicals_llc_behalf      6\n",
            "36727                      cheese_raw_milk      5\n",
            "87232                      mean_afm_levels      5\n",
            "159873        flavus_aspergillus_ochraceus      5\n",
            "406                      trace_afb_complex      5\n",
            "21445               homemade_soybean_paste      5\n",
            "71605     room_temperature_phosphorescence      5\n",
            "94720              imprinted_polymers_mips      5\n",
            "156460                 ci_ngl_respectively      5\n",
            "49606                    detection_afb_ota      5\n",
            "124444     aptasensor_successfully_applied      5\n",
            "96760          isolated_aspergillus_flavus      5\n",
            "145218              levels_total_aflatoxin      5\n",
            "75180             rapid_accurate_detection      5\n",
            "66885                          afb_ppb_ota      5\n",
            "\n",
            "期間: 2023-2025\n",
            "                                  word  count\n",
            "34737                  median_range_ng     10\n",
            "88157     advanced_veterinary_research      9\n",
            "720       graphical_abstract_presented      8\n",
            "116424                 group_gp_served      8\n",
            "30678                     gp_served_af      8\n",
            "58856       abstract_presented_authors      8\n",
            "58472                    gkg_wheat_gkg      8\n",
            "25079      presented_authors_exclusive      7\n",
            "130456                  corn_gkg_wheat      7\n",
            "33224                 rate_median_ngml      7\n",
            "63085                         sn_kg_ww      7\n",
            "109314    plantbased_meat_alternatives      7\n",
            "117182            flour_berbere_powder      7\n",
            "79846              shiro_flour_berbere      7\n",
            "91244                   afb_zen_within      6\n",
            "7416            culture_filtrates_skru      6\n",
            "64330                 treated_group_gp      6\n",
            "128385           detected_median_range      6\n",
            "82565          chinese_medicinal_herbs      6\n",
            "132506            zongye_essential_oil      6\n",
            "77221               linear_ranges_ngml      5\n",
            "1174            copper_albumin_complex      5\n",
            "54917     bentonite_fumonisin_esterase      5\n",
            "120560           lignin_treated_sodium      5\n",
            "41988               moldy_corn_kernels      5\n",
            "68394            heattreated_rice_bran      5\n",
            "22020            medicinal_edible_food      5\n",
            "51691                 dairy_cows_lambs      5\n",
            "9000                  de_part_springer      5\n",
            "385                           la_la_la      5\n",
            "58240                     gmbh_de_part      5\n",
            "82996         factor_erythroid_related      5\n",
            "117701         gold_nanoclusters_auncs      5\n",
            "101854  zeolitic_imidazolate_framework      5\n",
            "21494           springerverlag_gmbh_de      5\n",
            "116576           posing_serious_threat      5\n",
            "14369              hybrid_solar_drying      5\n",
            "62568              detection_limits_ng      5\n",
            "98872            detection_limits_pgml      5\n",
            "102659               cat_activity_mold      5\n",
            "14915                   peony_seed_oil      5\n",
            "142440        erythroid_related_factor      5\n",
            "67659                      taf_fum_ota      5\n",
            "94932              afm_detected_median      4\n",
            "130855       microbial_strains_enzymes      4\n",
            "123574   university_fujian_agriculture      4\n",
            "112640     jiangsu_university_zhejiang      4\n",
            "2100         inhibited_mycelial_growth      4\n",
            "101873    metabolites_contaminate_food      4\n",
            "127227            study_presents_novel      4\n"
          ]
        }
      ],
      "source": [
        "# @title 5. New Terms\n",
        "# Display new terms (unigrams)\n",
        "print(\"\\n=== Top 50 New Terms (Unigrams) ===\")\n",
        "for period in uni_new_terms:\n",
        "    # New terms\n",
        "    words = list(uni_new_terms[period])\n",
        "    # Get frequency counts\n",
        "    counts = [uni_freq_by_period[period][term] for term in words]\n",
        "    df_new = pd.DataFrame({\n",
        "        'word': words,\n",
        "        'count': counts\n",
        "    })\n",
        "    df_new = df_new.sort_values(by='count', ascending=False).head(50)\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_new[['word', 'count']])\n",
        "\n",
        "# Display new terms (bigrams)\n",
        "print(\"\\n=== Top 50 New Terms (Bigrams) ===\")\n",
        "for period in bi_new_terms:\n",
        "    words = list(bi_new_terms[period])\n",
        "    counts = [bi_freq_by_period[period][term] for term in words]\n",
        "    df_new = pd.DataFrame({\n",
        "        'word': words,\n",
        "        'count': counts\n",
        "    })\n",
        "    df_new = df_new.sort_values(by='count', ascending=False).head(50)\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_new[['word', 'count']])\n",
        "\n",
        "# Display new terms (trigrams)\n",
        "print(\"\\n=== Top 50 New Terms (Trigrams) ===\")\n",
        "for period in tri_new_terms:\n",
        "    words = list(tri_new_terms[period])\n",
        "    counts = [tri_freq_by_period[period][term] for term in words]\n",
        "    df_new = pd.DataFrame({\n",
        "        'word': words,\n",
        "        'count': counts\n",
        "    })\n",
        "    df_new = df_new.sort_values(by='count', ascending=False).head(50)\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_new[['word', 'count']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydkiwIaFEXnU",
        "outputId": "b94e9732-db54-4fc6-9a40-bf0ece7898be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 増加率の高い語句トップ50（単語） ===\n",
            "\n",
            "期間: 2017-2019\n",
            "               word  growth_rate (%)  count\n",
            "0         plantarum           3400.0     35\n",
            "1              pigs           3000.0     31\n",
            "2        intestinal           2700.0     56\n",
            "3            larvae           2300.0     24\n",
            "4               ros           2100.0     22\n",
            "5              coli           2000.0     42\n",
            "6               mip           1800.0     19\n",
            "7              afls           1800.0     19\n",
            "8               tht           1700.0     18\n",
            "9           piglets           1650.0     35\n",
            "10               zn           1600.0     17\n",
            "11            tract           1600.0     17\n",
            "12         severely           1600.0     17\n",
            "13            swine           1600.0     17\n",
            "14      escherichia           1600.0     17\n",
            "15           serbia           1500.0     32\n",
            "16         cellfree           1400.0     15\n",
            "17          weather           1400.0     15\n",
            "18          acetate           1400.0     15\n",
            "19         external           1400.0     15\n",
            "20  physicochemical           1400.0     15\n",
            "21     environments           1300.0     14\n",
            "22              fam           1300.0     14\n",
            "23        integrity           1300.0     14\n",
            "24          paprika           1300.0     14\n",
            "25           expert           1300.0     14\n",
            "26            beans           1300.0     28\n",
            "27       estimation           1300.0     14\n",
            "28         outcomes           1200.0     13\n",
            "29          insight           1200.0     13\n",
            "30        abundance           1200.0     13\n",
            "31            leads           1200.0     13\n",
            "32            third           1200.0     13\n",
            "33           insect           1200.0     26\n",
            "34           images           1200.0     13\n",
            "35       challenged           1200.0     13\n",
            "36          sativum           1200.0     13\n",
            "37               gm           1200.0     13\n",
            "38             date           1150.0     25\n",
            "39           villus           1100.0     12\n",
            "40         necrosis           1100.0     12\n",
            "41        chocolate           1100.0     12\n",
            "42            joint           1100.0     12\n",
            "43           rwanda           1100.0     12\n",
            "44            soils           1100.0     12\n",
            "45       polyphasic           1100.0     12\n",
            "46              bag           1100.0     12\n",
            "47            birth           1100.0     12\n",
            "48        ochraceus           1100.0     12\n",
            "49      challenging           1100.0     12\n",
            "\n",
            "期間: 2020-2022\n",
            "                word  growth_rate (%)  count\n",
            "0            licence           2900.0     30\n",
            "1                mgl           2800.0     29\n",
            "2        acidophilus           2300.0     24\n",
            "3          radiation           2300.0     24\n",
            "4                 cs           2200.0     23\n",
            "5       nanoemulsion           1900.0     20\n",
            "6      methylglyoxal           1800.0     19\n",
            "7                 ab           1600.0     17\n",
            "8                 cr           1600.0     17\n",
            "9            molitor           1500.0     16\n",
            "10                cy           1500.0     16\n",
            "11         exclusive           1450.0     31\n",
            "12       methylation           1400.0     15\n",
            "13             hptlc           1400.0     15\n",
            "14         catalytic           1400.0     15\n",
            "15         shellfish           1400.0     15\n",
            "16          kinetics           1300.0     14\n",
            "17         flavonoid           1300.0     14\n",
            "18         signaling           1300.0     14\n",
            "19  nanoencapsulated           1300.0     14\n",
            "20             loads           1300.0     14\n",
            "21          diabetes           1200.0     13\n",
            "22       categorized           1200.0     13\n",
            "23             goats           1200.0     13\n",
            "24     encapsulation           1100.0     24\n",
            "25              faso           1100.0     12\n",
            "26       aggregation           1100.0     12\n",
            "27        algorithms           1100.0     12\n",
            "28           prepare           1100.0     12\n",
            "29               mrs           1100.0     12\n",
            "30               ben           1100.0     12\n",
            "31       hydrophilic           1100.0     12\n",
            "32            lipase           1100.0     12\n",
            "33           burkina           1100.0     12\n",
            "34            latest           1100.0     12\n",
            "35               bcl           1000.0     11\n",
            "36               otb           1000.0     11\n",
            "37            glucan           1000.0     11\n",
            "38                bp           1000.0     11\n",
            "39           generic           1000.0     11\n",
            "40           advance           1000.0     11\n",
            "41           sausage           1000.0     11\n",
            "42     neurotoxicity            900.0     10\n",
            "43          infusion            900.0     10\n",
            "44            trfica            900.0     10\n",
            "45           novasil            900.0     10\n",
            "46         september            900.0     10\n",
            "47       mechanistic            900.0     10\n",
            "48                ha            900.0     10\n",
            "49           history            900.0     10\n",
            "\n",
            "期間: 2023-2025\n",
            "             word  growth_rate (%)  count\n",
            "0              la      3600.000000     37\n",
            "1          velvet      1800.000000     19\n",
            "2        sandwich      1800.000000     19\n",
            "3            vera      1700.000000     18\n",
            "4   licheniformis      1400.000000     15\n",
            "5              ps      1300.000000     14\n",
            "6     detoxifiers      1200.000000     13\n",
            "7     multitarget      1200.000000     13\n",
            "8             gum      1200.000000     13\n",
            "9          camels      1100.000000     12\n",
            "10         carrot      1100.000000     12\n",
            "11            crm      1100.000000     12\n",
            "12         flower      1000.000000     11\n",
            "13      autophagy      1000.000000     11\n",
            "14            paw      1000.000000     11\n",
            "15             ul       900.000000     10\n",
            "16      nanozymes       900.000000     10\n",
            "17             hb       900.000000     10\n",
            "18         mxenes       900.000000     10\n",
            "19     alteration       900.000000     10\n",
            "20       pericarp       900.000000     10\n",
            "21            pab       900.000000     10\n",
            "22    alleviating       900.000000     10\n",
            "23        drought       866.666667     29\n",
            "24       dualmode       850.000000     38\n",
            "25          algae       800.000000      9\n",
            "26        flowers       800.000000      9\n",
            "27         pikakt       800.000000      9\n",
            "28          feces       800.000000      9\n",
            "29      bisphenol       800.000000      9\n",
            "30       selenite       800.000000      9\n",
            "31     bimetallic       800.000000      9\n",
            "32        noodles       800.000000      9\n",
            "33       diseased       800.000000      9\n",
            "34            cds       800.000000     18\n",
            "35            hsi       750.000000     17\n",
            "36      pollutant       700.000000      8\n",
            "37        mucosal       700.000000      8\n",
            "38   nanoclusters       700.000000      8\n",
            "39           meju       700.000000      8\n",
            "40      templates       700.000000      8\n",
            "41       hairpins       700.000000      8\n",
            "42       rotation       700.000000      8\n",
            "43  collaboration       700.000000      8\n",
            "44   accomplished       700.000000      8\n",
            "45        sourced       700.000000      8\n",
            "46           ages       700.000000      8\n",
            "47             fl       700.000000      8\n",
            "48         intact       700.000000      8\n",
            "49        raisins       700.000000      8\n",
            "\n",
            "=== 増加率の高い語句トップ50（バイグラム） ===\n",
            "\n",
            "期間: 2017-2019\n",
            "                         word  growth_rate (%)  count\n",
            "0           determination_afb           2500.0     26\n",
            "1                 afb_induced           1600.0     17\n",
            "2                wheat_grains           1600.0     17\n",
            "3            escherichia_coli           1600.0     17\n",
            "4              effects_humans           1600.0     17\n",
            "5                     fed_afb           1500.0     16\n",
            "6                  easy_cheap           1500.0     16\n",
            "7             maize_groundnut           1500.0     16\n",
            "8                   afm_human           1400.0     15\n",
            "9             least_mycotoxin           1300.0     14\n",
            "10                  feed_food           1300.0     14\n",
            "11            fermented_foods           1300.0     14\n",
            "12               hazard_index           1200.0     13\n",
            "13            cheap_effective           1200.0     13\n",
            "14            study_indicated           1200.0     13\n",
            "15               corn_kernels           1200.0     13\n",
            "16           effective_rugged           1200.0     13\n",
            "17                afb_content           1200.0     13\n",
            "18                rugged_safe           1200.0     13\n",
            "19         produce_mycotoxins           1200.0     13\n",
            "20              afm_detection           1100.0     12\n",
            "21  acetyldeoxynivalenol_adon           1100.0     12\n",
            "22       metabolite_aflatoxin           1100.0     12\n",
            "23     gastrointestinal_tract           1100.0     12\n",
            "24                food_animal           1100.0     12\n",
            "25             storage_period           1100.0     12\n",
            "26                  aflr_afls           1100.0     12\n",
            "27         contaminated_least           1100.0     12\n",
            "28               simple_rapid           1100.0     12\n",
            "29          diet_contaminated           1000.0     11\n",
            "30             zearalenol_zol           1000.0     11\n",
            "31                   feed_afb           1000.0     11\n",
            "32             study_revealed           1000.0     11\n",
            "33                  milk_iran           1000.0     11\n",
            "34               liver_damage           1000.0     11\n",
            "35     fluorescence_quenching           1000.0     11\n",
            "36           expression_genes           1000.0     11\n",
            "37            afb_zearalenone           1000.0     11\n",
            "38    lactobacillus_plantarum           1000.0     11\n",
            "39             feed_additives           1000.0     11\n",
            "40         respectively_total           1000.0     11\n",
            "41      aflatoxigenic_strains           1000.0     11\n",
            "42        culture_supernatant            900.0     10\n",
            "43       crosssectional_study            900.0     10\n",
            "44      microbial_metabolites            900.0     10\n",
            "45        aflatoxins_detected            900.0     20\n",
            "46              faowho_expert            900.0     10\n",
            "47          expression_levels            900.0     10\n",
            "48       significant_increase            900.0     10\n",
            "49               joint_faowho            900.0     10\n",
            "\n",
            "期間: 2020-2022\n",
            "                        word  growth_rate (%)  count\n",
            "0             aflatoxin_mgkg           1600.0     17\n",
            "1         contamination_milk           1400.0     15\n",
            "2          hydrogen_peroxide           1300.0     14\n",
            "3            functional_food           1200.0     13\n",
            "4       aspergillus_isolates           1100.0     12\n",
            "5             support_vector           1100.0     12\n",
            "6               burkina_faso           1100.0     12\n",
            "7                     ml_low           1100.0     12\n",
            "8         mycotoxins_cereals           1100.0     12\n",
            "9              feed_matrices           1000.0     11\n",
            "10                 goat_milk           1000.0     11\n",
            "11       highly_contaminated           1000.0     11\n",
            "12            levels_samples           1000.0     11\n",
            "13       synergistic_effects           1000.0     11\n",
            "14               feed_supply           1000.0     11\n",
            "15            safety_quality           1000.0     11\n",
            "16          safety_standards           1000.0     11\n",
            "17     risk_characterization           1000.0     11\n",
            "18                    ngl_ci            900.0     10\n",
            "19  measured_highperformance            900.0     10\n",
            "20            afb_inhibitory            900.0     10\n",
            "21             high_accuracy            900.0     10\n",
            "22          health_therefore            900.0     10\n",
            "23              cancer_risks            900.0     10\n",
            "24      mycotoxins_detection            900.0     10\n",
            "25                cell_death            900.0     10\n",
            "26               samples_ota            900.0     10\n",
            "27                  milk_ngl            900.0     10\n",
            "28        confirmed_presence            900.0     10\n",
            "29            carcass_traits            900.0     10\n",
            "30              analysis_afm            900.0     10\n",
            "31                    ci_ngl            900.0     10\n",
            "32          fed_contaminated            800.0      9\n",
            "33                 risk_food            800.0      9\n",
            "34      detection_ochratoxin            800.0      9\n",
            "35                     ml_ml            800.0      9\n",
            "36      significant_positive            800.0      9\n",
            "37          samples_imported            800.0      9\n",
            "38                 seed_coat            800.0      9\n",
            "39       respectively_method            800.0      9\n",
            "40                   log_cfu            800.0      9\n",
            "41     positively_correlated            800.0      9\n",
            "42                work_aimed            800.0      9\n",
            "43    detection_technologies            800.0      9\n",
            "44         fb_deoxynivalenol            800.0      9\n",
            "45                feeds_feed            800.0      9\n",
            "46         species_belonging            800.0      9\n",
            "47        exposed_mycotoxins            800.0      9\n",
            "48       standards_authority            700.0      8\n",
            "49       detection_developed            700.0      8\n",
            "\n",
            "期間: 2023-2025\n",
            "                        word  growth_rate (%)  count\n",
            "0   prevalence_concentration           1800.0     19\n",
            "1                   afb_real           1400.0     15\n",
            "2              work_provides           1400.0     15\n",
            "3                 brown_rice           1200.0     13\n",
            "4               median_range           1200.0     13\n",
            "5      chemical_contaminants           1200.0     13\n",
            "6               solar_drying           1200.0     13\n",
            "7               sensor_based           1200.0     13\n",
            "8             novel_approach           1100.0     12\n",
            "9     antioxidant_properties           1000.0     11\n",
            "10        contamination_rice            900.0     10\n",
            "11                  high_afb            900.0     10\n",
            "12       advanced_veterinary            800.0      9\n",
            "13         presented_authors            800.0      9\n",
            "14        afs_concentrations            800.0      9\n",
            "15          signal_detection            800.0      9\n",
            "16          journal_advanced            800.0      9\n",
            "17      biological_processes            800.0      9\n",
            "18          however_presence            800.0      9\n",
            "19      significant_increase            750.0     17\n",
            "20            highlight_need            700.0      8\n",
            "21          developed_sensor            700.0      8\n",
            "22              target_genes            700.0      8\n",
            "23               method_good            700.0      8\n",
            "24          highly_effective            700.0      8\n",
            "25                zen_within            700.0      8\n",
            "26             poultry_farms            700.0      8\n",
            "27        storage_facilities            700.0      8\n",
            "28         cause_significant            700.0      8\n",
            "29          toxic_aflatoxins            700.0      8\n",
            "30        weather_conditions            700.0      8\n",
            "31         theoretical_basis            700.0      8\n",
            "32            challenge_food            700.0      8\n",
            "33         suspect_screening            700.0      8\n",
            "34     effectively_inhibited            700.0      8\n",
            "35            egg_production            700.0      8\n",
            "36    electrochemical_sensor            700.0      8\n",
            "37       contamination_poses            600.0      7\n",
            "38           control_methods            600.0      7\n",
            "39                 eu_limits            600.0      7\n",
            "40          afb_specifically            600.0      7\n",
            "41        blood_biochemistry            600.0      7\n",
            "42     adsorption_properties            600.0      7\n",
            "43         catalytic_hairpin            600.0      7\n",
            "44        growth_development            600.0     14\n",
            "45    transcriptome_analysis            600.0      7\n",
            "46            essential_food            600.0      7\n",
            "47                 limits_ng            600.0      7\n",
            "48        analysis_suggested            600.0      7\n",
            "49          chronic_diseases            600.0      7\n",
            "\n",
            "=== 増加率の高い語句トップ50（トライグラム） ===\n",
            "\n",
            "期間: 2017-2019\n",
            "                                  word  growth_rate (%)  count\n",
            "0                     quick_easy_cheap           1400.0     15\n",
            "1               cheap_effective_rugged           1200.0     13\n",
            "2                 easy_cheap_effective           1200.0     13\n",
            "3                effective_rugged_safe           1100.0     12\n",
            "4            growth_aspergillus_flavus           1000.0     11\n",
            "5             objective_study_evaluate           1000.0     11\n",
            "6                     afm_human_breast            900.0     10\n",
            "7                   afm_ochratoxin_ota            900.0     10\n",
            "8                  joint_faowho_expert            900.0     10\n",
            "9            aflatoxin_afb_zearalenone            900.0     10\n",
            "10                        gkg_mean_gkg            900.0     10\n",
            "11             faowho_expert_committee            900.0     10\n",
            "12                   fb_ochratoxin_ota            800.0      9\n",
            "13          samples_contaminated_least            800.0      9\n",
            "14               expert_committee_food            700.0      8\n",
            "15                     body_weight_per            700.0      8\n",
            "16                bovine_serum_albumin            700.0      8\n",
            "17                effects_human_animal            700.0      8\n",
            "18                 present_study_aimed            700.0      8\n",
            "19            committee_food_additives            700.0      8\n",
            "20                effects_human_health            700.0      8\n",
            "21               partial_least_squares            700.0      8\n",
            "22           detection_small_molecules            700.0      8\n",
            "23             present_study_conducted            700.0      8\n",
            "24  lateral_flow_immunochromatographic            700.0      8\n",
            "25          concentrations_ranging_gkg            700.0      8\n",
            "26                   graphene_oxide_go            700.0      8\n",
            "27      zearalenone_zen_deoxynivalenol            700.0      8\n",
            "28                      weight_per_day            700.0      8\n",
            "29               wiley_periodicals_inc            650.0     15\n",
            "30        contaminated_least_mycotoxin            600.0      7\n",
            "31                     hazard_index_hi            600.0      7\n",
            "32      deoxynivalenol_zearalenone_zea            600.0      7\n",
            "33                 margin_exposure_moe            600.0     14\n",
            "34                   linear_range_ngml            600.0      7\n",
            "35               limits_detection_lods            600.0      7\n",
            "36                    weight_gain_feed            600.0      7\n",
            "37                 afb_zearalenone_zen            600.0      7\n",
            "38           contamination_animal_feed            600.0      7\n",
            "39            lateral_flow_immunoassay            600.0      7\n",
            "40          aflatoxin_af_contamination            600.0      7\n",
            "41                  oxygen_species_ros            600.0      7\n",
            "42      mycotoxins_including_aflatoxin            500.0      6\n",
            "43         operational_taxonomic_units            500.0      6\n",
            "44           chemical_industry_society            500.0     18\n",
            "45            aspergillus_flavus_major            500.0      6\n",
            "46       fluorescence_detector_hplcfld            500.0      6\n",
            "47              infants_young_children            500.0      6\n",
            "48        inhibitory_concentration_mic            500.0      6\n",
            "49           industry_society_chemical            500.0     18\n",
            "\n",
            "期間: 2020-2022\n",
            "                                word  growth_rate (%)  count\n",
            "0         highly_sensitive_detection      1100.000000     12\n",
            "1              range_limit_detection      1000.000000     11\n",
            "2                         ngl_ci_ngl       900.000000     10\n",
            "3              food_safety_standards       900.000000     10\n",
            "4    measured_highperformance_liquid       900.000000     10\n",
            "5                 threat_food_safety       900.000000     10\n",
            "6                   ml_low_detection       800.000000      9\n",
            "7                children_aged_years       800.000000      9\n",
            "8      temperature_relative_humidity       700.000000      8\n",
            "9                 aflatoxin_afb_food       700.000000      8\n",
            "10               current_study_aimed       700.000000      8\n",
            "11       conditions_creative_commons       700.000000     24\n",
            "12            support_vector_machine       700.000000      8\n",
            "13               article_open_access       700.000000     24\n",
            "14         terms_conditions_creative       700.000000     24\n",
            "15      distributed_terms_conditions       666.666667     23\n",
            "16          switzerland_article_open       633.333333     22\n",
            "17          mdpi_switzerland_article       633.333333     22\n",
            "18   antifungal_aflatoxin_inhibitory       600.000000      7\n",
            "19           food_science_technology       600.000000      7\n",
            "20   simultaneous_detection_multiple       600.000000      7\n",
            "21                limit_set_european       600.000000      7\n",
            "22     secondary_metabolite_produced       600.000000      7\n",
            "23    contamination_authors_licensee       600.000000      7\n",
            "24          samples_authors_licensee       600.000000      7\n",
            "25         aflatoxins_afs_fumonisins       600.000000      7\n",
            "26                         ng_ml_low       600.000000      7\n",
            "27        study_designed_investigate       600.000000      7\n",
            "28            abstract_available_see       600.000000      7\n",
            "29            samples_analyzed_total       600.000000      7\n",
            "30         ghana_standards_authority       500.000000      6\n",
            "31   established_european_commission       500.000000      6\n",
            "32        agricultural_food_products       500.000000      6\n",
            "33              food_quality_control       500.000000      6\n",
            "34             potential_health_risk       500.000000      6\n",
            "35           significant_food_safety       500.000000      6\n",
            "36                  aim_study_assess       500.000000      6\n",
            "37               ngkg_body_weightday       500.000000      6\n",
            "38          favorable_safety_profile       500.000000      6\n",
            "39  determined_liquid_chromatography       500.000000      6\n",
            "40           raman_spectroscopy_sers       500.000000      6\n",
            "41           inhibited_growth_flavus       500.000000      6\n",
            "42      multiwalled_carbon_nanotubes       500.000000      6\n",
            "43        low_middleincome_countries       500.000000      6\n",
            "44                peanuts_peanut_oil       500.000000      6\n",
            "45              detection_limit_fgml       500.000000      6\n",
            "46                        ng_kg_body       500.000000      6\n",
            "47            confidence_interval_ci       500.000000      6\n",
            "48                 maximum_limit_set       500.000000      6\n",
            "49               infant_formula_milk       500.000000      6\n",
            "\n",
            "期間: 2023-2025\n",
            "                                           word  growth_rate (%)  count\n",
            "0                   journal_advanced_veterinary            800.0      9\n",
            "1                              food_safety_risk            700.0      8\n",
            "2                            red_pepper_samples            700.0      8\n",
            "3                      aptasensor_afb_detection            700.0      8\n",
            "4                       pose_significant_health            600.0      7\n",
            "5                significantly_inhibited_growth            600.0      7\n",
            "6                          ensuring_food_safety            600.0     14\n",
            "7                         complex_food_matrices            600.0      7\n",
            "8                          broiler_chickens_fed            600.0      7\n",
            "9                          aflatoxins_afs_toxic            500.0      6\n",
            "10                environmental_monitoring_food            500.0      6\n",
            "11                             system_food_feed            500.0      6\n",
            "12                regulated_emerging_mycotoxins            500.0      6\n",
            "13                    hyperspectral_imaging_hsi            500.0      6\n",
            "14                     pointofcare_testing_poct            500.0      6\n",
            "15                      mycotoxins_heavy_metals            500.0      6\n",
            "16                         food_safety_security            500.0     12\n",
            "17                            alert_system_food            500.0      6\n",
            "18                    density_functional_theory            500.0      6\n",
            "19                           detection_limit_nm            500.0      6\n",
            "20                       large_specific_surface            500.0      6\n",
            "21                              food_feed_rasff            500.0      6\n",
            "22                         mean_total_aflatoxin            500.0     12\n",
            "23                         detection_range_ngml            500.0      6\n",
            "24                           rapid_alert_system            500.0      6\n",
            "25                         degradation_rate_afb            400.0      5\n",
            "26                    optimal_conditions_linear            400.0      5\n",
            "27                   covalent_organic_framework            400.0      5\n",
            "28                         contaminated_ppb_afb            400.0      5\n",
            "29                           public_health_risk            400.0      5\n",
            "30                              sons_ltd_behalf            400.0      5\n",
            "31                       aflatoxin_levels_maize            400.0      5\n",
            "32                  medicine_university_tripoli            400.0      5\n",
            "33  liquid_chromatographyfluorescence_detection            400.0      5\n",
            "34              molecular_imprinting_technology            400.0      5\n",
            "35                      afbinduced_liver_injury            400.0      5\n",
            "36                   catalytic_hairpin_assembly            400.0      5\n",
            "37                      mass_spectrometry_icpms            400.0      5\n",
            "38                          carbon_quantum_dots            400.0      5\n",
            "39                         method_afb_detection            400.0      5\n",
            "40                     plasma_mass_spectrometry            400.0      5\n",
            "41                        total_aflatoxin_level            400.0      5\n",
            "42                    negative_control_positive            400.0      5\n",
            "43                            afm_levels_breast            400.0      5\n",
            "44                     pikakt_signaling_pathway            400.0      5\n",
            "45                          detection_range_afb            400.0      5\n",
            "46                method_simultaneous_detection            400.0      5\n",
            "47                           corn_flour_samples            400.0      5\n",
            "48                         wide_detection_range            350.0      9\n",
            "49                            nuts_dried_fruits            350.0      9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# @title 6. Terms with High Growth Rates\n",
        "# Display high growth rate terms (unigrams)\n",
        "print(\"\\n=== Top 50 Terms with High Growth Rates (Unigrams) ===\")\n",
        "for period in uni_growth_terms:\n",
        "    df_growth = pd.DataFrame({\n",
        "        'word': uni_growth_terms[period],\n",
        "        'growth_rate (%)': [uni_growth_rates[period][term] for term in uni_growth_terms[period]],\n",
        "        'count': [uni_growth_counts[period][term] for term in uni_growth_terms[period]],\n",
        "    })\n",
        "    df_growth = df_growth.sort_values(by='growth_rate (%)', ascending=False)\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_growth[['word', 'growth_rate (%)', 'count']])\n",
        "\n",
        "# Display high growth rate terms (bigrams)\n",
        "print(\"\\n=== Top 50 Terms with High Growth Rates (Bigrams) ===\")\n",
        "for period in bi_growth_terms:\n",
        "    df_growth = pd.DataFrame({\n",
        "        'word': bi_growth_terms[period],\n",
        "        'growth_rate (%)': [bi_growth_rates[period][term] for term in bi_growth_terms[period]],\n",
        "        'count': [bi_growth_counts[period][term] for term in bi_growth_terms[period]],\n",
        "    })\n",
        "    df_growth = df_growth.sort_values(by='growth_rate (%)', ascending=False)\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_growth[['word', 'growth_rate (%)', 'count']])\n",
        "\n",
        "# Display high growth rate terms (trigrams)\n",
        "print(\"\\n=== Top 50 Terms with High Growth Rates (Trigrams) ===\")\n",
        "for period in tri_growth_terms:\n",
        "    df_growth = pd.DataFrame({\n",
        "        'word': tri_growth_terms[period],\n",
        "        'growth_rate (%)': [tri_growth_rates[period][term] for term in tri_growth_terms[period]],\n",
        "        'count': [tri_growth_counts[period][term] for term in tri_growth_terms[period]],\n",
        "    })\n",
        "    df_growth = df_growth.sort_values(by='growth_rate (%)', ascending=False)\n",
        "    print(f\"\\nPeriod: {period}\")\n",
        "    print(df_growth[['word', 'growth_rate (%)', 'count']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-02k2MmmBsw",
        "outputId": "b2167cda-f848-4983-c57d-5019618e0b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== トピックの表示 ===\n",
            "トピック 1: afb, detection, aflatoxin, samples, method, food, mycotoxins, aflatoxins, results, ota, study, aflatoxin_afb, analysis, used, developed\n",
            "トピック 2: biochar, sn_kg, kg_ww, sn_kg_ww, mp_ingestion, csloeonp, ww, ibs, msat, oryzae_bl, afbngua, foqds, marbled_electric_ray, marbled_electric, electric_ray\n",
            "トピック 3: afm, milk, samples, milk_samples, ngl, dairy, raw_milk, raw, aflatoxin_afm, pasteurized, iran, kg, cheese, afm_milk, mean\n",
            "トピック 4: samples, gkg, mycotoxins, levels, feed, aflatoxin, aflatoxins, contamination, total, study, afs, ota, found, mycotoxin, food\n",
            "トピック 5: aflatoxin, food, contamination, samples, mycotoxins, aflatoxins, flavus, study, aspergillus, production, fungal, health, maize, levels, results\n"
          ]
        }
      ],
      "source": [
        "# @title 7. Topic Modeling (Including Unigrams and n-grams)\n",
        "# Step 6: Perform Topic Modeling\n",
        "\n",
        "# Setting the number of topics\n",
        "num_topics = 5  # Change as needed\n",
        "\n",
        "# Create dictionary and corpus (using all tokens)\n",
        "texts = df['all_tokens'].tolist()\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Create LDA model\n",
        "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10, random_state=42)\n",
        "\n",
        "# Retrieve topics (increase the number of words per topic)\n",
        "topics = lda_model.show_topics(num_topics=num_topics, num_words=15, formatted=False)\n",
        "\n",
        "# Display topics\n",
        "print(\"\\n=== Topics ===\")\n",
        "for idx, topic in topics:\n",
        "    topic_terms = ', '.join([term for term, _ in topic])\n",
        "    print(f\"Topic {idx+1}: {topic_terms}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YErMbOi8p9b",
        "outputId": "827f4805-2715-4e5a-d149-3b14d709f411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Comprehensive Analysis Using ChatGPT API\n",
        "\n",
        "# Instantiate the OpenAI client (set API key)\n",
        "client = OpenAI(api_key='')  # Enter your API key here\n",
        "\n",
        "# Instantiate the OpenAI client (set API key)\n",
        "#.api_key=''  # Enter your API key here\n",
        "\n",
        "# @title OpenAI API Settings\n",
        "# Setting the OpenAI API key\n",
        "# For security reasons, avoid hardcoding the API key in the code.\n",
        "# Use environment variables or another secure method.\n",
        "# Here, as an example, prompt the user for input.\n",
        "\n",
        "#import getpass\n",
        "\n",
        "#openai_api_key = getpass.getpass(\"Please enter your OpenAI API key: \")\n",
        "#openai.api_key = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Mb-AAU4H8KY",
        "outputId": "472acb13-d478-4aae-dc51-c0dce94cb958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 総合分析結果 ###\n",
            "\n",
            "以下、各タスクに沿って分析結果から読み取れる示唆と考察を述べる。\n",
            "\n",
            "──────────────────────────────\n",
            "1. 頻出語の分析\n",
            "\n",
            "・各期間とも「afb」「aflatoxin」「samples」「food」「detection」「mycotoxins／aflatoxins」などに高頻度が認められる。特に、2014–2016ではaflatoxin関連語が上位にランクインし、食品や飼料中のカビ毒検出に向けた方法論（chromatography、mass_spectrometryなど）への関心が示唆される。  \n",
            "・2017–2019、2020–2022、2023–2025と時期が進むにつれ、「method」や「analysis」「results」といった言及が引き続き高く、基礎的な定量分析および検出技術の改善が主要テーマとなっている。  \n",
            "・バイグラムやトライグラムでは「aflatoxin_afb」「liquid_chromatography」「highperformance_liquid_chromatography」など、実験手法や定量技術に焦点が当たっている。一方、後期になるほど「food_safety」「public_health」や「detection_limit」「ng_ml」など、実用的な安全基準や検出感度の向上を重視する傾向が強い。\n",
            "\n",
            "──────────────────────────────\n",
            "2. 新規出現語の分析\n",
            "\n",
            "・2014–2016期では、基礎的な語句（aflatoxin, method, studyなど）のほか、実験的な検出手法（immunosorbent_assay, chromatography_hplcなど）が新規に出現し、従来手法の発展を示唆。  \n",
            "・2017–2019期では、従来のaflatoxin関連ワードに加え、動物由来サンプル（donkey, piglets, intestinalなど）や食品加工、微生物群（cpa, cfs, eos, microbiomeなど）の言及が見受けられ、食品安全および動物健康への視点も拡大している。  \n",
            "・2020–2022期では、一部で「machine_learning」や「aptamer_sensor」など先端技術の示唆に加え、nanoemulsion、methylglyoxalといった化学的手法、環境中の汚染物質検出に関する語句が登場。  \n",
            "・2023–2025期では新たに「bpa」「az」「biochar」「nanopore」「microalgae」など、環境負荷やナノテクノロジーを含む新規領域が目立ち、食品安全のみならず環境汚染や持続可能性に関連する研究の波及が示唆される。\n",
            "\n",
            "──────────────────────────────\n",
            "3. 増加率の高い語句の分析\n",
            "\n",
            "・2017–2019期では、動物実験や腸内環境、微生物相（「plantarum」「pigs」「intestinal」など）の語句が急増しており、従来の食品中カビ毒検出と並行して、動物モデルや腸内フローラの影響を考慮した研究が進展している。  \n",
            "・バイグラムに関しては、「determination_afb」「escherichia_coli」など、従来よりも具体的・定量的なリスク評価や食中毒の因子が注目され、異なるサンプル群間比較やリスク指数の算出といった試みが見受けられる。  \n",
            "・2020–2022期では、単語レベルで「licence」「nanoemulsion」「methylglyoxal」などが急増しており、これは新たな分析機器の導入やナノテクノロジー、分子レベルの検査技術に対する需要の高まりが背景にあると考えられる。  \n",
            "・2023–2025期では、「la」「velvet」「sandwich」など、一見すると抽象的または特定分野の実験手法を示唆する語句が増加。バイグラムにおいても「prevalence_concentration」「afb_real」など、従来のaflatoxin研究と、より定量かつ実用的な評価の方向性が急速に重視される傾向が現れている。\n",
            "\n",
            "──────────────────────────────\n",
            "4. 主要な研究トピックの特定\n",
            "\n",
            "頻出語、新規出現語、増加率の高い語句、さらにトピックモデルの結果（以下の5トピック）を統合すると、以下の主要トピックが浮かび上がる：\n",
            "\n",
            "◇ トピック1： aflatoxin検出と評価  \n",
            "　– 高頻度に「afb」「aflatoxin」「detection」「method」「analysis」が登場。  \n",
            "　– 検出技術（液体クロマトグラフィー、質量分析法など）の開発・改善が主眼。\n",
            "\n",
            "◇ トピック2： 環境・食品安全管理と先端材料の利用  \n",
            "　– 「biochar」など環境負荷低減や汚染物質除去に関する新規出現語が示唆する。  \n",
            "　– 新素材やナノテクノロジーの導入が検出システムの革新に寄与。\n",
            "\n",
            "◇ トピック3： 乳製品およびデータ解析に基づく食品サンプルの評価  \n",
            "　– 「afm」「milk」「raw_milk」「dairy」など、乳製品に焦点を当てた研究が盛ん。  \n",
            "　– 検出感度の向上とともに、サンプル採取や前処理方法の最適化にも注力。\n",
            "\n",
            "◇ トピック4： 飼料および食品中のカビ毒とそのリスク評価  \n",
            "　– 「samples」「gkg」「contamination」「total」など、飼料や食品中のマイコトキシンの広域な分析が行われる。  \n",
            "　– リスク評価と安全基準確立のための定量化研究が背景にある。\n",
            "\n",
            "◇ トピック5： 生成過程や生産環境における微生物の役割と食品安全  \n",
            "　– 「flavus」「aspergillus」「production」「fungal」など、カビの生産環境や生理学的側面に焦点を当てる。  \n",
            "　– 食品中での微生物の影響評価や生産条件の最適化がテーマとなっている。\n",
            "\n",
            "──────────────────────────────\n",
            "5. 最新のトレンドと今後の展望\n",
            "\n",
            "【最新のトレンドおよび研究の注目点】\n",
            "・ 食品安全におけるaflatoxinやmycotoxinsの早期・高感度検出技術（液体クロマトグラフィー、質量分析法、aptasensor、electrochemical_sensor）の発展  \n",
            "・ 動物由来サンプルや腸内環境との関連付けによる、消費者の健康リスク評価研究の深化  \n",
            "・ ナノテクノロジー、nanoemulsion、nanoporeなど先端材料・技術の導入による、検出感度の向上と現場応用の拡大  \n",
            "・ 生産環境や食品加工工程中の微生物動態の解明、及びリスク管理のための定量的評価手法の確立  \n",
            "・ 環境汚染や持続可能性を意識したbiocharやmicroalgaeなど新規素材の活用による、食品安全・品質管理システムの構築\n",
            "\n",
            "──────────────────────────────\n",
            "6. 提言\n",
            "\n",
            "【今後の研究および応用に関する具体的な提言】\n",
            "① 高感度かつ現場適用可能なaflatoxin検出システムの開発を進め、食品・飼料の安全管理の迅速化を図る。  \n",
            "② 動物モデルや腸内フローラを含むヘルスリスク評価を統合したマルチディメンショナル解析手法を構築する。  \n",
            "③ ナノテクノロジーや機械学習（machine_learning, support_vector_machineなど）を活用した高度なデータ解析と検出アルゴリズムの研究を推進する。  \n",
            "④ 環境持続性や汚染物質低減に向けたbiocharやmicroalgaeなど新素材の応用研究を拡大し、食品サプライチェーン全体での安全性向上を目指す。  \n",
            "⑤ 異なるサンプルタイプ（例えば乳製品、飼料、野菜など）間での比較研究を強化し、多角的なリスク評価モデルの確立に寄与する。  \n",
            "⑥ 公衆衛生や環境政策に直結する基準設定のため、検出技術と実際のリスク評価データのフィードバックループを構築する。\n",
            "\n",
            "──────────────────────────────\n",
            "以上の分析結果から、aflatoxinおよび関連マイコトキシンに関する検出技術とリスク評価の高度化が中心課題であると同時に、ナノテクノロジーや先進計測技術、環境持続性へのアプローチが新たな潮流として浮上していることが明らかとなった。これにより、今後はより安全かつ迅速な食品検査体制の確立と、食品・飼料全体のリスクマネジメントの強化が求められる。\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3211a53e-7ac7-465f-8eb9-e5c97c213dca\", \"analysis_result.txt\", 8395)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title 8. Comprehensive Analysis Using ChatGPT API\n",
        "# Step 7: Comprehensive Analysis Using ChatGPT API\n",
        "# Compile the analysis results\n",
        "analysis_input = \"\"\n",
        "\n",
        "# Append frequent word information (unigrams, bigrams, trigrams)\n",
        "for period in periods:\n",
        "    analysis_input += f\"\\nTop 50 Frequent Unigrams ({period}):\\n\"\n",
        "    df_common_uni = uni_all_data[period]\n",
        "    analysis_input += df_common_uni[['word', 'count']].to_string(index=False)\n",
        "\n",
        "    analysis_input += f\"\\nTop 50 Frequent Bigrams ({period}):\\n\"\n",
        "    df_common_bi = bi_all_data[period]\n",
        "    analysis_input += df_common_bi[['word', 'count']].to_string(index=False)\n",
        "\n",
        "    analysis_input += f\"\\nTop 50 Frequent Trigrams ({period}):\\n\"\n",
        "    df_common_tri = tri_all_data[period]\n",
        "    analysis_input += df_common_tri[['word', 'count']].to_string(index=False)\n",
        "\n",
        "# Append new term information (unigrams, bigrams, trigrams)\n",
        "for period in periods:\n",
        "    # New terms (unigrams)\n",
        "    words_uni = list(uni_new_terms.get(period, []))\n",
        "    counts_uni = [uni_freq_by_period[period][term] for term in words_uni]\n",
        "    df_new_uni = pd.DataFrame({'word': words_uni, 'count': counts_uni}).sort_values(by='count', ascending=False).head(50)\n",
        "\n",
        "    # New terms (bigrams)\n",
        "    words_bi = list(bi_new_terms.get(period, []))\n",
        "    counts_bi = [bi_freq_by_period[period][term] for term in words_bi]\n",
        "    df_new_bi = pd.DataFrame({'word': words_bi, 'count': counts_bi}).sort_values(by='count', ascending=False).head(50)\n",
        "\n",
        "    # New terms (trigrams)\n",
        "    words_tri = list(tri_new_terms.get(period, []))\n",
        "    counts_tri = [tri_freq_by_period[period][term] for term in words_tri]\n",
        "    df_new_tri = pd.DataFrame({'word': words_tri, 'count': counts_tri}).sort_values(by='count', ascending=False).head(50)\n",
        "\n",
        "    analysis_input += f\"\\nNew Terms (Unigrams) ({period}):\\n\"\n",
        "    analysis_input += df_new_uni.to_string(index=False)\n",
        "    analysis_input += f\"\\nNew Terms (Bigrams) ({period}):\\n\"\n",
        "    analysis_input += df_new_bi.to_string(index=False)\n",
        "    analysis_input += f\"\\nNew Terms (Trigrams) ({period}):\\n\"\n",
        "    analysis_input += df_new_tri.to_string(index=False)\n",
        "    analysis_input += \"\\n\"\n",
        "\n",
        "# Append high growth rate term information (unigrams, bigrams, trigrams)\n",
        "for period in periods:\n",
        "    if period in uni_growth_terms:\n",
        "        # High growth rate terms (unigrams)\n",
        "        df_growth_uni = pd.DataFrame({\n",
        "            'word': uni_growth_terms[period],\n",
        "            'growth_rate (%)': [uni_growth_rates[period][term] for term in uni_growth_terms[period]],\n",
        "            'count': [uni_growth_counts[period][term] for term in uni_growth_terms[period]],\n",
        "        }).sort_values(by='growth_rate (%)', ascending=False).head(50)\n",
        "\n",
        "        # High growth rate terms (bigrams)\n",
        "        df_growth_bi = pd.DataFrame({\n",
        "            'word': bi_growth_terms[period],\n",
        "            'growth_rate (%)': [bi_growth_rates[period][term] for term in bi_growth_terms[period]],\n",
        "            'count': [bi_growth_counts[period][term] for term in bi_growth_terms[period]],\n",
        "        }).sort_values(by='growth_rate (%)', ascending=False).head(50)\n",
        "\n",
        "        # High growth rate terms (trigrams)\n",
        "        df_growth_tri = pd.DataFrame({\n",
        "            'word': tri_growth_terms[period],\n",
        "            'growth_rate (%)': [tri_growth_rates[period][term] for term in tri_growth_terms[period]],\n",
        "            'count': [tri_growth_counts[period][term] for term in tri_growth_terms[period]],\n",
        "        }).sort_values(by='growth_rate (%)', ascending=False).head(50)\n",
        "\n",
        "        analysis_input += f\"\\nHigh Growth Rate Terms (Unigrams) ({period}):\\n\"\n",
        "        analysis_input += df_growth_uni.to_string(index=False)\n",
        "        analysis_input += f\"\\nHigh Growth Rate Terms (Bigrams) ({period}):\\n\"\n",
        "        analysis_input += df_growth_bi.to_string(index=False)\n",
        "        analysis_input += f\"\\nHigh Growth Rate Terms (Trigrams) ({period}):\\n\"\n",
        "        analysis_input += df_growth_tri.to_string(index=False)\n",
        "        analysis_input += \"\\n\"\n",
        "\n",
        "# Append topic information\n",
        "analysis_input += \"\\nTopic Information:\\n\"\n",
        "for idx, topic in topics:\n",
        "    topic_terms = ', '.join([term for term, _ in topic])\n",
        "    analysis_input += f\"Topic {idx+1}: {topic_terms}\\n\"\n",
        "\n",
        "# Create the prompt\n",
        "prompt = f\"\"\"\n",
        "You are an expert in natural language processing and research trend analysis. Based on the data analysis results provided below, please deeply consider the research trends.\n",
        "\n",
        "### Data Analysis Results:\n",
        "\n",
        "{analysis_input}\n",
        "\n",
        "### Task:\n",
        "\n",
        "1. **Analysis of Frequent Words**:\n",
        "    - Analyze the top frequent words (unigrams, bigrams, trigrams) for each period and discuss the major research themes or trends indicated by these terms.\n",
        "2. **Analysis of New Terms**:\n",
        "    - For the top new terms (unigrams, bigrams, trigrams) for each period, consider the background of their appearance and the new research areas they suggest.\n",
        "3. **Analysis of Terms with High Growth Rates**:\n",
        "    - Analyze the terms with high growth rates (unigrams, bigrams, trigrams) for each period, discussing the factors behind their rapid increase and their impact on the research field.\n",
        "\n",
        "4. **Identification of Major Research Topics**:\n",
        "    - Integrate the frequent words, new terms, terms with high growth rates, and the results of the topic model to extract the major research topics, and explain their development and changes.\n",
        "\n",
        "5. **Recent Trends and Future Outlook**:\n",
        "    - Identify recent new trends and notable research areas, and discuss the potential impact on future research.\n",
        "\n",
        "6. **Recommendations**:\n",
        "    - Based on the analysis results, provide specific recommendations for future research or applications.\n",
        "\n",
        "### Constraints:\n",
        "- Do not include any items not mentioned in the analysis results.\n",
        "- If the analysis contains publisher or author details, ignore them as they are words that should have been removed.\n",
        "\n",
        "### Description of the Results:\n",
        "\n",
        "- The analysis should be described concisely and logically, including specific figures or examples.\n",
        "- For the recent trends, future outlook, and recommendations, summarize the key trends or points in a bullet list of 5 to 10 items.\n",
        "\"\"\"\n",
        "# Generate the analysis using the ChatGPT API\n",
        "response = client.chat.completions.create(\n",
        "    model=\"o3-mini-2025-01-31\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a data scientist with advanced analytical skills.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    )\n",
        "\n",
        "# Retrieve the generated analysis result\n",
        "analysis_result = response.choices[0].message.content.strip()\n",
        "\n",
        "# Display the analysis result\n",
        "print(\"\\n### Comprehensive Analysis Result ###\\n\")\n",
        "print(analysis_result)\n",
        "\n",
        "# Save the analysis result to a text file\n",
        "with open('analysis_result.txt', 'w', encoding='utf-8') as f:\n",
        "  f.write(analysis_result)\n",
        "# Download the text file\n",
        "files.download('analysis_result.txt')  # Confirm that 'files' has been imported from google.colab\n",
        "\n",
        "# @title 9. Upload and Read Existing Review Papers\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload multiple PDF files of review papers for comparison.\")\n",
        "uploaded_reviews = files.upload()\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "# Store the text of review papers in a list\n",
        "review_texts = []\n",
        "for file_name in uploaded_reviews.keys():\n",
        "    with open(file_name, 'rb') as f:\n",
        "        text = extract_text_from_pdf(f)\n",
        "        review_texts.append(text)\n",
        "\n",
        "# Create a dataframe for the text data\n",
        "reviews_df = pd.DataFrame({'Review_Title': list(uploaded_reviews.keys()), 'Text': review_texts})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "jFFxtCuGTsoV",
        "outputId": "397dd349-d95b-4a61-d2e7-0769bf6a64f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "比較対象となるレビュー論文のPDFファイルを複数アップロードしてください。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-08c67482-cbbd-45d3-994a-876af7f2e62f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-08c67482-cbbd-45d3-994a-876af7f2e62f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fmicb-11-01916.pdf to fmicb-11-01916.pdf\n",
            "Saving foods-09-00518.pdf to foods-09-00518.pdf\n",
            "Saving foods-12-00527.pdf to foods-12-00527.pdf\n"
          ]
        }
      ],
      "source": [
        "# @title 9. Upload and Read Existing Review Papers\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload multiple PDF files of review papers for comparison.\")\n",
        "uploaded_reviews = files.upload()\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "# Store the text of review papers in a list\n",
        "review_texts = []\n",
        "for file_name in uploaded_reviews.keys():\n",
        "    with open(file_name, 'rb') as f:\n",
        "        text = extract_text_from_pdf(f)\n",
        "        review_texts.append(text)\n",
        "\n",
        "# Create a dataframe for the text data\n",
        "reviews_df = pd.DataFrame({'Review_Title': list(uploaded_reviews.keys()), 'Text': review_texts})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx8rUEdojMWG",
        "outputId": "391c97f0-4d30-4ad8-e5aa-99e6cbcfd7eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# @title 10. Summarization and Key Points Extraction from Review Papers\n",
        "import openai\n",
        "\n",
        "# Setting the OpenAI API key (it is recommended to use environment variables or other secure methods)\n",
        "#openai.api_key = 'YOUR_OPENAI_API_KEY'  # It is recommended to load from environment variables\n",
        "\n",
        "def summarize_text(text, max_length=1500):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"o3-mini-2025-01-31\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an experienced researcher skilled at summarizing scientific papers.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Please concisely summarize the key points of the following review paper.\\n\\n{text}\"}\n",
        "        ],\n",
        "    )\n",
        "    summary = response.choices[0].message.content.strip()\n",
        "    return summary\n",
        "\n",
        "# Generate a summary for each review paper\n",
        "reviews_df['Summary'] = reviews_df['Text'].apply(lambda x: summarize_text(x))\n",
        "\n",
        "# Extraction of major trends or themes\n",
        "def extract_key_points(summary):\n",
        "    prompt = f\"\"\"\n",
        "    From the following summary, extract the major research trends or themes in bullet points.\n",
        "\n",
        "    ### Summary:\n",
        "    {summary}\n",
        "\n",
        "    ### Extracted Points:\n",
        "    - List 3 to 5 major trends or themes in bullet points.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"o3-mini-2025-01-31\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a researcher with advanced natural language processing skills.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        )\n",
        "    key_points = response.choices[0].message.content.strip()\n",
        "    return key_points\n",
        "\n",
        "reviews_df['Key_Points'] = reviews_df['Summary'].apply(lambda x: extract_key_points(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "7ApmgNY6kgwi",
        "outputId": "9b1f26b4-31b3-4bea-f10a-3fdf69080539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 妥当性評価レポート ###\n",
            "\n",
            "### 1. 整合性の評価：\n",
            "\n",
            "#### 一致点：\n",
            "- **サンプル前処理技術**：\n",
            "  - あなたのデータ分析結果の「新規出現語の分析」や「増加率の高い語句の分析」で「QuEChERS」や「液液抽出」、「固相抽出」といった前処理技術が頻繁に出現し、レビュー論文2、3、4でもこれらの技術の重要性が強調されています。\n",
            "  \n",
            "- **分離・検出技術の進展**：\n",
            "  - トピックモデリングで抽出された「クロマトグラフィー」や「MS/MS」などの技術は、レビュー論文全体で高感度な分析法として繰り返し言及されています。特にLC-MS/MSに関する言及が多く、一貫したトレンドが見られます。\n",
            "\n",
            "- **免疫学的手法とバイオセンサー技術**：\n",
            "  - データ分析結果には「ELISA」や「バイオセンサー」に関連する語句が含まれ、レビュー論文2、3でもこれらの技術が現場での迅速なスクリーニングに利用されているとされています。\n",
            "\n",
            "#### 一致していない点：\n",
            "- **新素材や先端技術**：\n",
            "  - レビュー論文3には「新素材を利用した固相抽出」や「プロテオミクス・ゲノミクス」といった先端技術の活用について言及されていますが、あなたのデータ分析ではこれらの要素が明確に抽出されていないようです。\n",
            "\n",
            "- **自動化・ミニチュア化**：\n",
            "  - レビュー論文2で将来のトレンドとして「自動化・ミニチュア化」が挙げられていますが、あなたのデータ分析結果にはこの点に特化した語句が見当たりません。\n",
            "\n",
            "### 2. 手法の妥当性：\n",
            "\n",
            "あなたの分析手法は、主要な研究トピックの抽出において一定の妥当性を示しています。特に、頻出語やトピックモデリングによる主要テーマは、レビュー論文での傾向と一致しており、データの分析精度が高いと評価できます。しかし、全体的な技術の進展や将来のトレンドを捉えるにはやや弱い部分も見受けられます。特に、新素材の利用や自動化の流れなど、細分化されたトピックの抽出が不足しています。\n",
            "\n",
            "### 3. 改善点の提案：\n",
            "\n",
            "#### 強み：\n",
            "- 頻出語やトピックモデリングを用いた分析により、レビュー論文で言及される主要な技術や手法を正確に捉えています。\n",
            "- 新規出現語や増加率の高い語句の分析によって、技術の進化や新たなトレンドを一定程度把握できています。\n",
            "\n",
            "#### 改善が必要な点：\n",
            "- **細分化されたトピックの抽出**：\n",
            "  - 新素材の利用や自動化・ミニチュア化といった細かい技術トレンドの検出には、より詳細なテキスト解析手法（例えば、ディープラーニングを用いた文章意味解析など）を導入することが有効です。\n",
            "\n",
            "- **レビュー論文との比較の強化**：\n",
            "  - データ分析結果とレビュー論文の比較をより体系的に行うため、レビュー論文の内容をカテゴリ別に抽出し、それに基づいた分析を行うと、一致点や相違点をより明確に把握できます。\n",
            "\n",
            "このように、分析の精度を高めるためには、より細やかなテキスト解析技術の導入とレビュー論文との比較方法の工夫が求められます。\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c62bea31-af1f-4a02-b949-f2d7370387a5\", \"validation_report.txt\", 3474)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title 11. Comparison of Data Analysis Results and Trends/Themes from Review Papers\n",
        "# Create a summary of your analysis results\n",
        "your_analysis_summary = \"\"\"\n",
        "### Summary of Your Data Analysis Results:\n",
        "1. **Frequent Words Analysis**:\n",
        "    - A list of top frequent words (unigrams, bigrams, trigrams) for each period.\n",
        "2. **New Terms Analysis**:\n",
        "    - A list of top new terms (unigrams, bigrams, trigrams) for each period.\n",
        "3. **High Growth Rate Terms Analysis**:\n",
        "    - A list of terms with high growth rates (unigrams, bigrams, trigrams) for each period.\n",
        "4. **Major Research Topics**:\n",
        "    - The major research topics extracted from the topic modeling results.\n",
        "\"\"\"\n",
        "\n",
        "# Combine key points from review papers\n",
        "review_key_points = reviews_df['Key_Points'].tolist()\n",
        "review_combined_key_points = \"\\n\".join([f\"### Major Trends or Themes for Review Paper {i+1}:\\n{kp}\" for i, kp in enumerate(review_key_points, 1)])\n",
        "\n",
        "# Create the comparison prompt\n",
        "comparison_prompt = f\"\"\"\n",
        "You are an expert in evaluating the validity of research methodologies. Based on the following data analysis results and the major trends or themes extracted from existing review papers, please compare them and evaluate the validity of your analysis method.\n",
        "\n",
        "### Your Data Analysis Results:\n",
        "{your_analysis_summary}\n",
        "\n",
        "### Major Trends or Themes from Review Papers:\n",
        "{review_combined_key_points}\n",
        "\n",
        "### Task:\n",
        "\n",
        "1. **Evaluation of Consistency**:\n",
        "    - Assess the degree of agreement between your data analysis results and the trends/themes from the review papers.\n",
        "    - Specify the points of agreement and disagreement.\n",
        "\n",
        "2. **Validity of the Method**:\n",
        "    - Based on the points of agreement and disagreement, assess how valid your analysis method is.\n",
        "\n",
        "3. **Suggestions for Improvement**:\n",
        "    - Discuss the strengths of your analysis method and the areas that need improvement.\n",
        "\n",
        "### Constraints:\n",
        "- Do not include any information not mentioned in the review papers.\n",
        "- Use specific figures or examples from the analysis results and review papers in your evaluation.\n",
        "\n",
        "### Description of the Results:\n",
        "- Present the evaluation in a concise and logical manner, clearly addressing each evaluation point.\n",
        "\"\"\"\n",
        "\n",
        "# Generate the evaluation using ChatGPT\n",
        "response_comparison = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an experienced expert in evaluating research methodologies.\"},\n",
        "        {\"role\": \"user\", \"content\": comparison_prompt}\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=2000,\n",
        ")\n",
        "\n",
        "comparison_result = response_comparison.choices[0].message.content.strip()\n",
        "\n",
        "# Display the evaluation result\n",
        "print(\"\\n### Validity Evaluation Report ###\\n\")\n",
        "print(comparison_result)\n",
        "\n",
        "# Save the evaluation report to a text file\n",
        "with open('validation_report.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(comparison_result)\n",
        "\n",
        "# Download the text file\n",
        "files.download('validation_report.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "xHElzUgPkjsT",
        "outputId": "eb00220a-1a04-4e68-a1f2-0de0ed35f15b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 詳細な妥当性評価レポート ###\n",
            "\n",
            "### 詳細な妥当性評価\n",
            "\n",
            "#### 一致点の評価：\n",
            "\n",
            "1. **サンプル前処理技術**：\n",
            "   - **理由と背景**：QuEChERSや液液抽出、固相抽出は、分析化学における標準的なサンプル前処理技術です。これらの技術は多くの研究分野で広く用いられ、分析の精度と効率を向上させるために不可欠です。レビュー論文でもこれらの技術が繰り返し強調されているのは、これらが確立された手法であることを示しています。\n",
            "   - **評価**：あなたのデータ分析結果がこれらの技術を頻繁に取り上げていることは、分析手法が主要な研究傾向を正確に反映していることを示しており、その妥当性が確認できます。\n",
            "\n",
            "2. **分離・検出技術の進展**：\n",
            "   - **理由と背景**：クロマトグラフィーやMS/MS（特にLC-MS/MS）は高感度で高精度な分析が可能なため、多くの研究で採用されています。これらの技術は、複雑なサンプルマトリックスからの成分分離と定量において非常に有効です。\n",
            "   - **評価**：データ分析結果がこれらの技術を強調している点は、現代の分析技術の進展を正確に捉えていることを示し、レビュー論文の内容と整合性が高いです。\n",
            "\n",
            "3. **免疫学的手法とバイオセンサー技術**：\n",
            "   - **理由と背景**：ELISAやバイオセンサーは、迅速かつ簡便な分析が可能で、多くのフィールドにおけるスクリーニングに活用されています。特に、現場での即時分析の必要性が高まる中で、その利用が増加しているのは自然な流れです。\n",
            "   - **評価**：分析結果にこれらの技術が含まれていることは、技術の実用性と現場でのニーズに対応していることを示し、妥当性が支持されます。\n",
            "\n",
            "#### 一致していない点の評価：\n",
            "\n",
            "1. **新素材や先端技術**：\n",
            "   - **理由と背景**：レビュー論文3で言及される新素材やプロテオミクス・ゲノミクスは、比較的新しい研究領域であり、特定の専門分野に限定される可能性があります。これにより、一般的なデータセットではこれらのトピックが明確に抽出されにくい状況が考えられます。\n",
            "   - **評価**：あなたのデータ分析でこれらが抽出されていないことは、データセットの特異性や分析手法の焦点が一般的な技術に偏っている可能性を示唆しています。\n",
            "\n",
            "2. **自動化・ミニチュア化**：\n",
            "   - **理由と背景**：自動化・ミニチュア化のトレンドは、技術革新により進められていますが、これらはまだ発展途上であり、文献での言及が限られている可能性があります。\n",
            "   - **評価**：これらのトピックが分析結果に現れていないことは、現時点でのデータセットの限界や分析手法の改良の必要性を示しています。\n",
            "\n",
            "### 手法の改善提案\n",
            "\n",
            "1. **細分化されたトピックの抽出**：\n",
            "   - **提案**：ディープラーニングを用いた自然言語処理（NLP）技術を導入し、文脈的な理解を深めることで、より細分化されたトピックの抽出を可能にします。特に、新素材や自動化に関連する特定のキーワードやフレーズをターゲットにしたテキスト解析を行うことが有効です。\n",
            "\n",
            "2. **レビュー論文との比較の強化**：\n",
            "   - **提案**：レビュー論文の内容をさらに詳細に分類し、特定のカテゴリ（例：新素材、自動化、環境影響など）に基づいた比較を行うことで、分析の深度を増すことができます。これは、トピックの網羅性を高め、一致点や相違点をよりクリアに把握するのに役立ちます。\n",
            "\n",
            "### 総合的な結論\n",
            "\n",
            "あなたの分析手法は、主要な研究トピックの抽出において高い妥当性を示しています。特に、既存の技術や手法に関する分析は、レビュー論文との一致が見られ、分析の精度が高いと評価できます。しかし、技術の進展や新たなトレンドに関する分析の精度を向上させるためには、より高度なテキスト解析技術の導入が求められます。\n",
            "\n",
            "今後の研究に向けた展望としては、データ分析手法の改良に加え、レビュー論文の内容を詳細に分析し、新たなトレンドを早期に捉えることが重要です。これにより、分析の網羅性と精度を高め、技術の進展を包括的に理解することが可能になるでしょう。客観的なデータに基づいた評価を行うことで、より正確な研究の方向性を見出すことができます。\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c237b5a9-9c4b-4558-aa6b-71004e71624b\", \"detailed_validation_report.txt\", 4921)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title 12. Detailed Validity Evaluation Report (Optional)\n",
        "# Since a report was generated in Step 3, this section is for further customization if needed.\n",
        "# For example, create a prompt to further detail the evaluation of the method.\n",
        "\n",
        "additional_prompt = f\"\"\"\n",
        "Below is the comparison result between your data analysis results and the major trends or themes extracted from existing review papers. Based on this information, please provide a more detailed evaluation of the validity of your method.\n",
        "\n",
        "### Comparison Result:\n",
        "{comparison_result}\n",
        "\n",
        "### Task:\n",
        "\n",
        "1. **Detailed Validity Evaluation**:\n",
        "    - For each point of agreement and disagreement, provide detailed reasons and background.\n",
        "\n",
        "2. **Method Improvement Suggestions**:\n",
        "    - Considering the identified discrepancies, propose improvements or new approaches for the analysis method.\n",
        "\n",
        "3. **Overall Conclusion**:\n",
        "    - Summarize the overall validity of your analysis method and provide your outlook for future research.\n",
        "\n",
        "### Constraints:\n",
        "- Provide specific examples based on the review papers and data analysis results.\n",
        "- Ensure the evaluation is objective and data-driven.\n",
        "\n",
        "### Description of the Results:\n",
        "- Present your evaluation in a concise and logical manner, clearly addressing each evaluation point.\n",
        "\"\"\"\n",
        "\n",
        "# Generate a detailed evaluation using ChatGPT\n",
        "response_additional = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an experienced expert in evaluating research methodologies.\"},\n",
        "        {\"role\": \"user\", \"content\": additional_prompt}\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=2000,\n",
        ")\n",
        "\n",
        "additional_comparison_result = response_additional.choices[0].message.content.strip()\n",
        "\n",
        "# Display the detailed evaluation result\n",
        "print(\"\\n### Detailed Validity Evaluation Report ###\\n\")\n",
        "print(additional_comparison_result)\n",
        "\n",
        "# Save the detailed evaluation report to a text file\n",
        "with open('detailed_validation_report.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(additional_comparison_result)\n",
        "\n",
        "# Download the text file\n",
        "files.download('detailed_validation_report.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CSryNp3AtE9_",
        "outputId": "d9b1947e-a918-415c-c8de-2e104bb7d0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5843688a-bcf6-435b-9410-e4078118f5d8\", \"all_terms_analysis_results.xlsx\", 53983)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title 13. Save the Results\n",
        "# Step 10: Save the results (export to an Excel file)\n",
        "try:\n",
        "    with pd.ExcelWriter('all_terms_analysis_results.xlsx', engine='xlsxwriter') as writer:\n",
        "        # Save frequent unigrams to a sheet\n",
        "        for period, df_common in uni_all_data.items():\n",
        "            sheet_name = f'Uni_Frequent_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Uni_Freq_{period[:4]}-{period[-4:]}'\n",
        "            df_common.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save frequent bigrams to a sheet\n",
        "        for period, df_common in bi_all_data.items():\n",
        "            sheet_name = f'Bi_Frequent_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Bi_Freq_{period[:4]}-{period[-4:]}'\n",
        "            df_common.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save frequent trigrams to a sheet\n",
        "        for period, df_common in tri_all_data.items():\n",
        "            sheet_name = f'Tri_Frequent_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Tri_Freq_{period[:4]}-{period[-4:]}'\n",
        "            df_common.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save new terms (unigrams) to a sheet\n",
        "        for period, new_terms in uni_new_terms.items():\n",
        "            words = list(new_terms)\n",
        "            counts = [uni_freq_by_period[period][term] for term in words]\n",
        "            df_new = pd.DataFrame({\n",
        "                'word': words,\n",
        "                'count': counts\n",
        "            }).sort_values(by='count', ascending=False).head(50)\n",
        "            sheet_name = f'Uni_New_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Uni_New_{period[:4]}-{period[-4:]}'\n",
        "            df_new.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save new terms (bigrams) to a sheet\n",
        "        for period, new_terms in bi_new_terms.items():\n",
        "            words = list(new_terms)\n",
        "            counts = [bi_freq_by_period[period][term] for term in words]\n",
        "            df_new = pd.DataFrame({\n",
        "                'word': words,\n",
        "                'count': counts\n",
        "            }).sort_values(by='count', ascending=False).head(50)\n",
        "            sheet_name = f'Bi_New_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Bi_New_{period[:4]}-{period[-4:]}'\n",
        "            df_new.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save new terms (trigrams) to a sheet\n",
        "        for period, new_terms in tri_new_terms.items():\n",
        "            words = list(new_terms)\n",
        "            counts = [tri_freq_by_period[period][term] for term in words]\n",
        "            df_new = pd.DataFrame({\n",
        "                'word': words,\n",
        "                'count': counts\n",
        "            }).sort_values(by='count', ascending=False).head(50)\n",
        "            sheet_name = f'Tri_New_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Tri_New_{period[:4]}-{period[-4:]}'\n",
        "            df_new.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save high growth rate terms (unigrams) to a sheet\n",
        "        for period, terms in uni_growth_terms.items():\n",
        "            df_growth = pd.DataFrame({\n",
        "                'word': terms,\n",
        "                'growth_rate (%)': [uni_growth_rates[period][term] for term in terms],\n",
        "                'count': [uni_growth_counts[period][term] for term in terms],\n",
        "            }).sort_values(by='growth_rate (%)', ascending=False).head(50)\n",
        "            sheet_name = f'Uni_Growth_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Uni_Growth_{period[:4]}-{period[-4:]}'\n",
        "            df_growth.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save high growth rate terms (bigrams) to a sheet\n",
        "        for period, terms in bi_growth_terms.items():\n",
        "            df_growth = pd.DataFrame({\n",
        "                'word': terms,\n",
        "                'growth_rate (%)': [bi_growth_rates[period][term] for term in terms],\n",
        "                'count': [bi_growth_counts[period][term] for term in terms],\n",
        "            }).sort_values(by='growth_rate (%)', ascending=False).head(50)\n",
        "            sheet_name = f'Bi_Growth_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Bi_Growth_{period[:4]}-{period[-4:]}'\n",
        "            df_growth.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save high growth rate terms (trigrams) to a sheet\n",
        "        for period, terms in tri_growth_terms.items():\n",
        "            df_growth = pd.DataFrame({\n",
        "                'word': terms,\n",
        "                'growth_rate (%)': [tri_growth_rates[period][term] for term in terms],\n",
        "                'count': [tri_growth_counts[period][term] for term in terms],\n",
        "            }).sort_values(by='growth_rate (%)', ascending=False).head(50)\n",
        "            sheet_name = f'Tri_Growth_{period}'\n",
        "            if len(sheet_name) > 31:\n",
        "                sheet_name = f'Tri_Growth_{period[:4]}-{period[-4:]}'\n",
        "            df_growth.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Save topic information to a sheet\n",
        "        topic_list = []\n",
        "        for idx, topic in topics:\n",
        "            topic_terms = ', '.join([term for term, _ in topic])\n",
        "            topic_list.append({'Topic': f'Topic {idx+1}', 'Terms': topic_terms})\n",
        "        df_topics = pd.DataFrame(topic_list)\n",
        "        df_topics.to_excel(writer, sheet_name='Topics', index=False)\n",
        "\n",
        "        # Save the generated analysis result to a sheet\n",
        "        df_analysis_result = pd.DataFrame({'Analysis Result': [analysis_result]})\n",
        "        df_analysis_result.to_excel(writer, sheet_name='Analysis_Result', index=False)\n",
        "\n",
        "        # Save the validation result to a sheet\n",
        "        ##df_validation_result = pd.DataFrame({'Validation Result': [validation_result]})\n",
        "        ##df_validation_result.to_excel(writer, sheet_name='Validation_Result', index=False)\n",
        "\n",
        "    # Download the file (if using Google Colab)\n",
        "    files.download('all_terms_analysis_results.xlsx')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCfhqQaQXip3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNgkr0zKrwR27Z/c5ieNu5V",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}